{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b65d4a7b-2de4-4b35-b493-ecc70493ec81",
   "metadata": {},
   "source": [
    "This notebook is used to create synthetic abstracts with corresponding entities and relations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1b79a86-c608-4d1c-ba6d-543999e85dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries to import\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import torch\n",
    "import re\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from copy import deepcopy\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65687d53-4982-415d-bf05-6ca79816f2dd",
   "metadata": {},
   "source": [
    "# Step 1: Parse the Train.PubTator file to get entities, normalized entities, and relations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4feaa250-1eec-46a8-8877-c269c590759d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number total entity triples: 13351\n",
      "number unique entity triples: 4806\n",
      "unique entity types: {'CellLine', 'ChemicalEntity', 'DiseaseOrPhenotypicFeature', 'OrganismTaxon', 'SequenceVariant', 'GeneOrGeneProduct'}\n",
      "number unique entity types: 6\n",
      "number unique normalized entities: 2642\n",
      "unique coarse relation triples: {('Positive_Correlation', 'SequenceVariant', 'ChemicalEntity'), ('Positive_Correlation', 'DiseaseOrPhenotypicFeature', 'GeneOrGeneProduct'), ('Drug_Interaction', 'ChemicalEntity', 'ChemicalEntity'), ('Negative_Correlation', 'SequenceVariant', 'DiseaseOrPhenotypicFeature'), ('Association', 'SequenceVariant', 'GeneOrGeneProduct'), ('Association', 'SequenceVariant', 'ChemicalEntity'), ('Positive_Correlation', 'GeneOrGeneProduct', 'ChemicalEntity'), ('Association', 'ChemicalEntity', 'GeneOrGeneProduct'), ('Association', 'ChemicalEntity', 'ChemicalEntity'), ('Positive_Correlation', 'GeneOrGeneProduct', 'GeneOrGeneProduct'), ('Association', 'DiseaseOrPhenotypicFeature', 'ChemicalEntity'), ('Negative_Correlation', 'GeneOrGeneProduct', 'DiseaseOrPhenotypicFeature'), ('Positive_Correlation', 'ChemicalEntity', 'DiseaseOrPhenotypicFeature'), ('Association', 'DiseaseOrPhenotypicFeature', 'GeneOrGeneProduct'), ('Bind', 'ChemicalEntity', 'GeneOrGeneProduct'), ('Positive_Correlation', 'SequenceVariant', 'DiseaseOrPhenotypicFeature'), ('Conversion', 'ChemicalEntity', 'ChemicalEntity'), ('Cotreatment', 'ChemicalEntity', 'ChemicalEntity'), ('Association', 'GeneOrGeneProduct', 'ChemicalEntity'), ('Association', 'SequenceVariant', 'DiseaseOrPhenotypicFeature'), ('Positive_Correlation', 'ChemicalEntity', 'SequenceVariant'), ('Association', 'GeneOrGeneProduct', 'GeneOrGeneProduct'), ('Positive_Correlation', 'GeneOrGeneProduct', 'DiseaseOrPhenotypicFeature'), ('Bind', 'GeneOrGeneProduct', 'ChemicalEntity'), ('Positive_Correlation', 'DiseaseOrPhenotypicFeature', 'SequenceVariant'), ('Association', 'ChemicalEntity', 'DiseaseOrPhenotypicFeature'), ('Negative_Correlation', 'ChemicalEntity', 'ChemicalEntity'), ('Bind', 'GeneOrGeneProduct', 'GeneOrGeneProduct'), ('Negative_Correlation', 'GeneOrGeneProduct', 'GeneOrGeneProduct'), ('Negative_Correlation', 'ChemicalEntity', 'GeneOrGeneProduct'), ('Comparison', 'ChemicalEntity', 'ChemicalEntity'), ('Negative_Correlation', 'DiseaseOrPhenotypicFeature', 'ChemicalEntity'), ('Negative_Correlation', 'SequenceVariant', 'ChemicalEntity'), ('Negative_Correlation', 'DiseaseOrPhenotypicFeature', 'GeneOrGeneProduct'), ('Association', 'SequenceVariant', 'SequenceVariant'), ('Association', 'ChemicalEntity', 'SequenceVariant'), ('Association', 'GeneOrGeneProduct', 'DiseaseOrPhenotypicFeature'), ('Association', 'DiseaseOrPhenotypicFeature', 'SequenceVariant'), ('Negative_Correlation', 'GeneOrGeneProduct', 'ChemicalEntity'), ('Positive_Correlation', 'ChemicalEntity', 'GeneOrGeneProduct'), ('Positive_Correlation', 'ChemicalEntity', 'ChemicalEntity'), ('Negative_Correlation', 'ChemicalEntity', 'DiseaseOrPhenotypicFeature'), ('Positive_Correlation', 'DiseaseOrPhenotypicFeature', 'ChemicalEntity')}\n",
      "number unique coarse relation triples 43\n",
      "CPU times: user 50.9 ms, sys: 3.94 ms, total: 54.9 ms\n",
      "Wall time: 56.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pub_tator_file = \"data/Train.PubTator\"\n",
    "pub_tator_lines = None\n",
    "with open(pub_tator_file,\"r\") as f:\n",
    "    pub_tator_lines = f.readlines()\n",
    "\"\"\"\n",
    "print(\"PubTator head:\")\n",
    "print(pub_tator_lines[:100])\n",
    "print(\"End of PubTator head\")\n",
    "\"\"\"\n",
    "pmid_ids = []\n",
    "curr_pmid_id = None\n",
    "titles = []\n",
    "abstracts = []\n",
    "entity_lists = [] # each list: list of (entity type, normalized entity, mention) triples\n",
    "relation_lists = [] # each list: list of (relation, head, tail triples)\n",
    "curr_ent_list = []\n",
    "curr_rel_list = []\n",
    "def get_pmid(line):\n",
    "    pmid_len = 8 # maximum length\n",
    "    while True:\n",
    "        try:\n",
    "            return int(line[:pmid_len])\n",
    "        except:\n",
    "            # pmid is shorter than 8 digits\n",
    "            if pmid_len <= 0:\n",
    "                print(\"something went wrong\")\n",
    "                return\n",
    "            pmid_len -= 1 # try doing it shorter\n",
    "\n",
    "def find_index_non_numeric(line):\n",
    "    result = 0\n",
    "    char = line[result]\n",
    "    while char in ['0','1','2','3','4','5','6','7','8','9']:\n",
    "        result += 1\n",
    "        char = line[result]\n",
    "    return result\n",
    "\n",
    "def extract_norm_ent(string):\n",
    "    # sometimes normalized entites come in comma list because\n",
    "    # the annotators couldn't narrow it down to a single\n",
    "    # normalized concept. For simplicity, just take the first\n",
    "    # such entity.\n",
    "    if ',' not in string:\n",
    "        return string\n",
    "    return string.split(',')[0]\n",
    "    \n",
    "for line in pub_tator_lines:\n",
    "    if line != '\\n':\n",
    "        # Get the numbers at the start of the line\n",
    "        pmid_id = get_pmid(line)\n",
    "        if pmid_id != curr_pmid_id:\n",
    "            # If there is a change, add any new data to the lists of lists\n",
    "            if len(curr_ent_list) > 0:\n",
    "                # okay if no new relations\n",
    "                # some abstracts may not have new relations\n",
    "                entity_lists.append(curr_ent_list)\n",
    "                curr_ent_list = []\n",
    "                relation_lists.append(curr_rel_list)\n",
    "                curr_rel_list = []\n",
    "            # Add new pmid to the pmid list\n",
    "            pmid_ids.append(pmid_id)\n",
    "            # Change the current pmid id\n",
    "            curr_pmid_id = pmid_id\n",
    "        # Check to see if it is a title, abstract, entity, or relation line\n",
    "        first_i_after_num = find_index_non_numeric(line)\n",
    "        if line[first_i_after_num] == '|':\n",
    "            # title or abstract \n",
    "            next_char = line[first_i_after_num + 1]\n",
    "            if next_char == 't': \n",
    "                # title\n",
    "                title = line[first_i_after_num+3:].strip()\n",
    "                titles.append(title)\n",
    "            elif next_char == 'a':\n",
    "                # abstract \n",
    "                abstract = line[first_i_after_num+3:].strip()\n",
    "                abstracts.append(abstract)\n",
    "            else:\n",
    "                print(\"something went wrong processing | ... Printing line:\")\n",
    "                print(line[:50])\n",
    "                print(\"The line before the next character:\",line[:first_i_after_num])\n",
    "                print(\"The next character:\",next_char)\n",
    "        else:\n",
    "            # entity or relation\n",
    "            split_line = (line.strip()).split('\\t')\n",
    "            #print(\"split_line:\",split_line)\n",
    "            # index 0: pmid. index 1: start offset for entity, relation type for relation\n",
    "            try:\n",
    "                first_span = int(split_line[1]) # if this works, it is for an entity\n",
    "                #print(\"entity\")\n",
    "                ent_type = split_line[4]\n",
    "                norm_ent = extract_norm_ent(split_line[5])\n",
    "                mention = split_line[3]\n",
    "                curr_ent_list.append((ent_type,norm_ent,mention))\n",
    "            except ValueError:\n",
    "                # split_line[1] is not an int -> relation\n",
    "                #print(\"relation\")\n",
    "                rel_type = split_line[1]\n",
    "                head_norm_ent = split_line[2]\n",
    "                tail_norm_ent = split_line[3]\n",
    "                curr_rel_list.append((rel_type,head_norm_ent,tail_norm_ent))\n",
    "# By the end of the loop, there is still some entities and relations not added\n",
    "entity_lists.append(curr_ent_list)\n",
    "relation_lists.append(curr_rel_list)\n",
    "    \n",
    "\"\"\"\n",
    "print(\"Head of titles:\")\n",
    "print(titles[:5])\n",
    "print(\"End of titles head\")\n",
    "print(\"Head of abstracts:\")\n",
    "print(abstracts[:5])\n",
    "print(\"End of abstracts head\")\n",
    "print(\"Head of entities:\")\n",
    "print(entity_lists[:5])\n",
    "print(\"End of entities head\")\n",
    "print(\"Head of relations\")\n",
    "print(relation_lists[:5])\n",
    "print(\"End of relations head\")\n",
    "\"\"\"\n",
    "\n",
    "# How that we have all this information, we can aggregate it\n",
    "# to form a useful template for our synthetic data. \n",
    "# We need to know: no. entities per document, no. rels per document,\n",
    "# All possible (ent_type, norm_ent, mention) triples. For added\n",
    "# diversity, instead of sampling from the standard distribution of\n",
    "# these triples, we can sample from ent_type uniformly, then norm_ent\n",
    "# uniformly, then mention uniformly. \n",
    "\n",
    "def vis_hist(values,message):\n",
    "    print(message)\n",
    "    plt.hist(values,density=True)\n",
    "    plt.show()\n",
    "    \n",
    "def num_unique(a_list,index):\n",
    "    # Number of uniuqe instances of values at index i in a_list\n",
    "    return len(set(map(lambda x: x[index],a_list)))\n",
    "\n",
    "def find_ent_type(norm_ent,ent_list):\n",
    "    for ent_triple in ent_list:\n",
    "        if ent_triple[1] == norm_ent:\n",
    "            return ent_triple[0]\n",
    "    #print(\"couldn't find the entity...\")\n",
    "    #print(\"the entity was:\",norm_ent)\n",
    "    return None\n",
    "\n",
    "num_ents_per_doc = list(map(lambda x: len(x), entity_lists))\n",
    "num_ent_classes_per_doc = list(map(lambda x: num_unique(x,0), entity_lists))\n",
    "num_norm_ents_per_doc = list(map(lambda x: num_unique(x,1), entity_lists))\n",
    "\n",
    "#vis_hist(num_ents_per_doc,\"Number entities per document:\")\n",
    "#vis_hist(num_ent_classes_per_doc,\"Number entity classes per document:\")\n",
    "#vis_hist(num_norm_ents_per_doc,\"Number unique normalized entities per document:\")\n",
    "\n",
    "num_rels_per_doc = list(map(lambda x: len(x), relation_lists))\n",
    "num_unique_rels_per_doc = list(map(lambda x: num_unique(x,0), relation_lists))\n",
    "\n",
    "#vis_hist(num_rels_per_doc,\"Number relations per document:\")\n",
    "#vis_hist(num_unique_rels_per_doc,\"Number unique relation classes per document\")\n",
    "\n",
    "all_entity_triples = []\n",
    "for entity_list in entity_lists:\n",
    "    all_entity_triples.extend(entity_list)\n",
    "print(\"number total entity triples:\",len(all_entity_triples))\n",
    "unique_entity_triples = set(all_entity_triples)\n",
    "print(\"number unique entity triples:\",len(unique_entity_triples))\n",
    "unique_ent_types = set(map(lambda x: x[0], unique_entity_triples))\n",
    "print(\"unique entity types:\",unique_ent_types)\n",
    "print(\"number unique entity types:\",len(unique_ent_types))\n",
    "unique_ent_doublets = set(map(lambda x: x[:2], unique_entity_triples)) # normalized entities\n",
    "print(\"number unique normalized entities:\",len(unique_ent_doublets))\n",
    "all_coarse_rel_triples = [] # coarse: head and tail entity types\n",
    "coarse_grain_rel_triples_per_doc = [] # this distribution is important\n",
    "for i in range(len(relation_lists)):\n",
    "    curr_rel_list = relation_lists[i]\n",
    "    curr_ent_list = entity_lists[i]\n",
    "    curr_coarse_grain_rel_triples = []\n",
    "    for j in range(len(curr_rel_list)):\n",
    "        curr_rel_triple = curr_rel_list[j]\n",
    "        curr_rel = curr_rel_triple[0]\n",
    "        curr_head = find_ent_type(curr_rel_triple[1],curr_ent_list)\n",
    "        curr_tail = find_ent_type(curr_rel_triple[2],curr_ent_list)\n",
    "        if curr_head != None and curr_tail != None:\n",
    "            all_coarse_rel_triples.append((curr_rel,curr_head,curr_tail))\n",
    "            curr_coarse_grain_rel_triples.append((curr_rel,curr_head,curr_tail))\n",
    "    coarse_grain_rel_triples_per_doc.append(curr_coarse_grain_rel_triples)\n",
    "unique_coarse_rel_triples = set(all_coarse_rel_triples)\n",
    "print(\"unique coarse relation triples:\",unique_coarse_rel_triples)\n",
    "print(\"number unique coarse relation triples\",len(unique_coarse_rel_triples))\n",
    "\n",
    "num_unique_coarse_grained = list(map(lambda x: len(set(x)),coarse_grain_rel_triples_per_doc))\n",
    "#vis_hist(num_unique_coarse_grained, \"Number unique coarse grained relations per doc:\")\n",
    "\n",
    "# Plan: for prompt: use sampling to determine number of entity classes,\n",
    "# then number of normalized entities, then number of mentions per document.\n",
    "# Sample uniformly from possible entity classes, then normalized entities;\n",
    "# pick all mentions for normalized entity to be the same for simplicity.\n",
    "# Then pick number of relation classes (unique relations) and number of \n",
    "# individual relations, sample these from uniform. Finally, tell this to\n",
    "# LLM. Using an example might be good. Afterwards, check for entities by\n",
    "# exact match and make sure counts are off by no more than 20%. Use these\n",
    "# exact matches to build the corresponding PubTator file.\n",
    "\n",
    "def get_dist(vals):\n",
    "    # Return (options,p)\n",
    "    ct = Counter(vals)\n",
    "    keys = sorted(ct.keys())\n",
    "    options = []\n",
    "    p = []\n",
    "    tot = ct.total()\n",
    "    for i in range(len(keys)):\n",
    "        options.append(keys[i])\n",
    "        p.append(ct[keys[i]]/tot)\n",
    "    return options, p\n",
    "\n",
    "def generate_ge_than(options,p,val_ge_than):\n",
    "    result = np.random.choice(options,1,p=p)[0]\n",
    "    while result < val_ge_than:\n",
    "        result = np.random.choice(options,1,p=p)[0]\n",
    "    return result\n",
    "\n",
    "def get_synthetic_ents_and_rels():\n",
    "    # Randomly determined each time.\n",
    "    # First, generate number of entity types, normalized entities, and entity mentions\n",
    "    ent_type_dist = get_dist(num_ent_classes_per_doc)\n",
    "    num_ent_types = np.random.choice(ent_type_dist[0],1,p=ent_type_dist[1])[0]\n",
    "    norm_ent_dist = get_dist(num_norm_ents_per_doc)\n",
    "    num_norm_ent = generate_ge_than(norm_ent_dist[0],norm_ent_dist[1],num_ent_types)\n",
    "    mention_dist = get_dist(num_ents_per_doc)\n",
    "    num_mention = generate_ge_than(mention_dist[0],mention_dist[1],num_norm_ent)\n",
    "    #print(\"entity nums:\",(num_ent_types,num_norm_ent,num_mention))\n",
    "    #return (num_ent_types, num_norm_ent, num_mention) # testing\n",
    "    # Now, determine what the entity types, normalized entities, and mentions\n",
    "    # actually are. For mentions they can all be the same for the same normalized\n",
    "    # entity to make it easier for the synthetic data generator.\n",
    "    unique_ent_types_lst = list(unique_ent_types)\n",
    "    ent_types_is = np.random.choice(len(unique_ent_types_lst), num_ent_types, replace = False)\n",
    "    selected_ent_types = list(map(lambda x: unique_ent_types_lst[x], ent_types_is))\n",
    "    #print(\"selected ent types:\",selected_ent_types)\n",
    "    # For each selected entity type, determine the set of normalized entities from which to sample.\n",
    "    norm_ent_dict = dict()\n",
    "    for ent_type in selected_ent_types:\n",
    "        norm_ent_dict[ent_type] = list({ele[1] for ele in unique_ent_doublets if ele[0] == ent_type})\n",
    "    # Perform sampling. Need at least 1 from each category, then add more.\n",
    "    selected_ent_doublets = []\n",
    "    for ent_type in selected_ent_types:\n",
    "        a_norm_ent = np.random.choice(norm_ent_dict[ent_type],1)[0]\n",
    "        selected_ent_doublets.append((ent_type,a_norm_ent))\n",
    "    for i in range(len(norm_ent_dict),num_norm_ent):\n",
    "        a_ent_type = np.random.choice(selected_ent_types,1)[0]\n",
    "        a_norm_ent = np.random.choice(norm_ent_dict[a_ent_type],1)[0]\n",
    "        selected_ent_doublets.append((a_ent_type,a_norm_ent))\n",
    "    #print(\"selected doublets:\",selected_ent_doublets)\n",
    "    # I think above here is fine; there is a bug below here\n",
    "    # Do similar thing with mentions, but only selected one mention per normalized entity. \n",
    "    mention_dict = dict()\n",
    "    selected_ent_triples = []\n",
    "    for ent_doublet in selected_ent_doublets:\n",
    "        possible_mentions = list({ele[2] for ele in unique_entity_triples if ele[:2] == ent_doublet})\n",
    "        mention_dict[ent_doublet] = np.random.choice(possible_mentions,1)[0]\n",
    "        selected_ent_triples.append((ent_doublet[0],ent_doublet[1],mention_dict[ent_doublet])) # alreday adds first few mentions\n",
    "    for i in range(len(mention_dict),num_mention):\n",
    "        rand_index = np.random.choice(len(selected_ent_doublets),1)[0]\n",
    "        a_ent_doublet = selected_ent_doublets[rand_index]\n",
    "        selected_ent_triples.append((a_ent_doublet[0],a_ent_doublet[1],mention_dict[a_ent_doublet])) \n",
    "    #print(\"selected entity triples:\",selected_ent_triples)\n",
    "    # Now the entity triples have been successfully generated. It is now\n",
    "    # time to generate the relations.\n",
    "    # Determine number of unique coarse-grained relations, then number of total relations.\n",
    "    unique_cg_rel_dist = get_dist(num_unique_coarse_grained)\n",
    "    num_unique_cg_rels = np.random.choice(unique_cg_rel_dist[0],1,p=unique_cg_rel_dist[1])[0]\n",
    "    tot_rel_dist = get_dist(num_rels_per_doc)\n",
    "    num_tot_rels = generate_ge_than(tot_rel_dist[0],tot_rel_dist[1],num_unique_cg_rels) \n",
    "    #print(\"rel nums:\",(num_unique_cg_rels,num_tot_rels))\n",
    "    # Now actually sample from number of unique cg_rels. Need to determine which ones\n",
    "    # are possible given the entities.\n",
    "    possible_cg_rels = []\n",
    "    for rel in unique_coarse_rel_triples:\n",
    "        if (rel[1] in selected_ent_types) and (rel[2] in selected_ent_types):\n",
    "            possible_cg_rels.append(rel) \n",
    "    num_unique_cg_rels = min(num_unique_cg_rels, len(possible_cg_rels)) # can't have more rels than possible!\n",
    "    #print(\"now, rel nums:\",(num_unique_cg_rels,num_tot_rels))\n",
    "    selected_cg_rel_is = np.random.choice(len(possible_cg_rels),num_unique_cg_rels,replace=False)\n",
    "    selected_cg_rels = []\n",
    "    for i in selected_cg_rel_is:\n",
    "        selected_cg_rels.append(possible_cg_rels[i])\n",
    "    #print(\"selected cg rels:\",selected_cg_rels)\n",
    "    # Now do the same thing with total rels. These are actually unique. \n",
    "    possible_rels = []\n",
    "    for rel in selected_cg_rels:\n",
    "        rel_type = rel[0]\n",
    "        head_ent_type = rel[1]\n",
    "        possible_norm_heads = list(set({ele[1] for ele in selected_ent_doublets if ele[0] == head_ent_type}))\n",
    "        tail_ent_type = rel[2]\n",
    "        possible_norm_tails = list(set({ele[1] for ele in selected_ent_doublets if ele[0] == tail_ent_type}))\n",
    "        for poss_head in possible_norm_heads:\n",
    "            for poss_tail in possible_norm_tails:\n",
    "                # Make sure the head and tail aren't the same before adding\n",
    "                if poss_head != poss_tail:\n",
    "                    possible_rels.append((rel_type,poss_head,poss_tail))\n",
    "    #print(\"number of possible relations:\",len(possible_rels))\n",
    "    num_tot_rels = min(num_tot_rels,len(possible_rels))  \n",
    "    #print(\"now, rel nums:\",(num_unique_cg_rels,num_tot_rels))\n",
    "    selected_rel_is =  np.random.choice(len(possible_rels),num_tot_rels,replace=False)\n",
    "    selected_rels = []\n",
    "    for i in selected_rel_is:\n",
    "        selected_rels.append(possible_rels[i])\n",
    "    #print(\"selected rels:\",selected_rels) \n",
    "    \n",
    "    # Finally, output selected entities and selected relations\n",
    "    # Returning a counter for selected entity triples will make \n",
    "    # my life easier because duplicates exist. \n",
    "    return (Counter(selected_ent_triples), selected_rels)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dff681a-17a3-4f8b-b652-e9f7f22539be",
   "metadata": {},
   "source": [
    "# Step 2: Generate prompts for LLM and output synthetic data to a file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22f78ce6-da6f-4d75-a093-d698743b4461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4536b024decd4bdcae4e37197c65498f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM finished loading\n"
     ]
    }
   ],
   "source": [
    "# Setup LLM. Note that this need to be done on amperenodes so there's enough GPU memory.\n",
    "model_dir = \"Qwen3-8B/\"\n",
    "model = AutoModelForCausalLM.from_pretrained(            \n",
    "                                            model_dir,\n",
    "                                            torch_dtype=\"auto\", \n",
    "                                            device_map=\"auto\"\n",
    "                                            )\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "print(\"LLM finished loading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63455233-c604-4046-a186-b082efeff891",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "generated synthetic entities and relations\n",
      "generated user prompt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated response\n",
      "parsed response\n",
      "output to pubtator file\n",
      "output to csv file\n",
      "Completed abstract 1 of 500\n",
      "---------------------------------\n",
      "generated synthetic entities and relations\n",
      "generated user prompt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated response\n",
      "parsed response\n",
      "output to pubtator file\n",
      "output to csv file\n",
      "Completed abstract 2 of 500\n",
      "---------------------------------\n",
      "generated synthetic entities and relations\n",
      "generated user prompt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated response\n",
      "parsed response\n",
      "output to pubtator file\n",
      "output to csv file\n",
      "Completed abstract 3 of 500\n",
      "---------------------------------\n",
      "generated synthetic entities and relations\n",
      "generated user prompt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated response\n",
      "parsed response\n",
      "output to pubtator file\n",
      "output to csv file\n",
      "Completed abstract 4 of 500\n",
      "---------------------------------\n",
      "generated synthetic entities and relations\n",
      "generated user prompt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated response\n",
      "parsed response\n",
      "output to pubtator file\n",
      "output to csv file\n",
      "Completed abstract 5 of 500\n",
      "---------------------------------\n",
      "generated synthetic entities and relations\n",
      "generated user prompt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated response\n",
      "parsed response\n",
      "output to pubtator file\n",
      "output to csv file\n",
      "Completed abstract 6 of 500\n",
      "---------------------------------\n",
      "generated synthetic entities and relations\n",
      "generated user prompt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated response\n",
      "parsed response\n",
      "output to pubtator file\n",
      "output to csv file\n",
      "Completed abstract 7 of 500\n",
      "---------------------------------\n",
      "generated synthetic entities and relations\n",
      "generated user prompt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated response\n",
      "parsed response\n",
      "output to pubtator file\n",
      "output to csv file\n",
      "Completed abstract 8 of 500\n",
      "---------------------------------\n",
      "generated synthetic entities and relations\n",
      "generated user prompt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated response\n",
      "parsed response\n",
      "output to pubtator file\n",
      "output to csv file\n",
      "Completed abstract 9 of 500\n",
      "---------------------------------\n",
      "generated synthetic entities and relations\n",
      "generated user prompt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 191\u001b[0m\n\u001b[1;32m    189\u001b[0m u_prompt \u001b[38;5;241m=\u001b[39m generate_user_prompt(synthetic_ents, synthetic_rels)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerated user prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 191\u001b[0m response \u001b[38;5;241m=\u001b[39m generate_LLM_response(model,tokenizer,u_prompt)\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerated response\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    193\u001b[0m parsed_response, llm_ent_ct \u001b[38;5;241m=\u001b[39m parse_llm_response(response,synthetic_ents,synthetic_rels)\n",
      "Cell \u001b[0;32mIn[9], line 73\u001b[0m, in \u001b[0;36mgenerate_LLM_response\u001b[0;34m(model, tokenizer, user_prompt)\u001b[0m\n\u001b[1;32m     66\u001b[0m text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mapply_chat_template(\n\u001b[1;32m     67\u001b[0m     messages,\n\u001b[1;32m     68\u001b[0m     tokenize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     69\u001b[0m     add_generation_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     70\u001b[0m     enable_thinking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;66;03m# False for debug purposes\u001b[39;00m\n\u001b[1;32m     71\u001b[0m )\n\u001b[1;32m     72\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m tokenizer([text], return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 73\u001b[0m generated_ids \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs,\n\u001b[1;32m     75\u001b[0m     max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32768\u001b[39m, \u001b[38;5;66;03m# maximum w/o yarn for Qwen3\u001b[39;00m\n\u001b[1;32m     76\u001b[0m     do_sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;66;03m# deterministic. ok because prompts are stochastic.\u001b[39;00m\n\u001b[1;32m     77\u001b[0m )\n\u001b[1;32m     78\u001b[0m generated_ids \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     79\u001b[0m     output_ids[\u001b[38;5;28mlen\u001b[39m(input_ids):] \u001b[38;5;28;01mfor\u001b[39;00m input_ids, output_ids \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(model_inputs\u001b[38;5;241m.\u001b[39minput_ids, generated_ids)\n\u001b[1;32m     80\u001b[0m ]\n\u001b[1;32m     81\u001b[0m response \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(generated_ids, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/generation_vijay2/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/generation_vijay2/lib/python3.11/site-packages/transformers/generation/utils.py:2597\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[1;32m   2589\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2590\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2591\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2592\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2593\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2594\u001b[0m     )\n\u001b[1;32m   2596\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2597\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample(\n\u001b[1;32m   2598\u001b[0m         input_ids,\n\u001b[1;32m   2599\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[1;32m   2600\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mprepared_stopping_criteria,\n\u001b[1;32m   2601\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[1;32m   2602\u001b[0m         synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[1;32m   2603\u001b[0m         streamer\u001b[38;5;241m=\u001b[39mstreamer,\n\u001b[1;32m   2604\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2605\u001b[0m     )\n\u001b[1;32m   2607\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2608\u001b[0m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[1;32m   2609\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2610\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2611\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   2612\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2613\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2614\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/generation_vijay2/lib/python3.11/site-packages/transformers/generation/utils.py:3560\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3558\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   3559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3560\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   3562\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[1;32m   3563\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   3564\u001b[0m     outputs,\n\u001b[1;32m   3565\u001b[0m     model_kwargs,\n\u001b[1;32m   3566\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   3567\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/generation_vijay2/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/generation_vijay2/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/generation_vijay2/lib/python3.11/site-packages/transformers/utils/generic.py:969\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_top_level_module\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 969\u001b[0m     output \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    970\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[1;32m    971\u001b[0m         output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[0;32m~/.conda/envs/generation_vijay2/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py:730\u001b[0m, in \u001b[0;36mQwen3ForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m output_hidden_states \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    726\u001b[0m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39moutput_hidden_states\n\u001b[1;32m    727\u001b[0m )\n\u001b[1;32m    729\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m--> 730\u001b[0m outputs: BaseModelOutputWithPast \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[1;32m    731\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    732\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m    733\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m    734\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[1;32m    735\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[1;32m    736\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m    737\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    738\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m    739\u001b[0m     cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    741\u001b[0m )\n\u001b[1;32m    743\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[1;32m    744\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/generation_vijay2/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/generation_vijay2/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/generation_vijay2/lib/python3.11/site-packages/transformers/utils/generic.py:969\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_top_level_module\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 969\u001b[0m     output \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    970\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[1;32m    971\u001b[0m         output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[0;32m~/.conda/envs/generation_vijay2/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py:463\u001b[0m, in \u001b[0;36mQwen3Model.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[1;32m    461\u001b[0m     all_hidden_states \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (hidden_states,)\n\u001b[0;32m--> 463\u001b[0m layer_outputs \u001b[38;5;241m=\u001b[39m decoder_layer(\n\u001b[1;32m    464\u001b[0m     hidden_states,\n\u001b[1;32m    465\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mcausal_mask,\n\u001b[1;32m    466\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m    467\u001b[0m     past_key_value\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[1;32m    468\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    469\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m    470\u001b[0m     cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[1;32m    471\u001b[0m     position_embeddings\u001b[38;5;241m=\u001b[39mposition_embeddings,\n\u001b[1;32m    472\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mflash_attn_kwargs,\n\u001b[1;32m    473\u001b[0m )\n\u001b[1;32m    475\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/.conda/envs/generation_vijay2/lib/python3.11/site-packages/transformers/modeling_layers.py:48\u001b[0m, in \u001b[0;36mGradientCheckpointingLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_checkpointing \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/generation_vijay2/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/generation_vijay2/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/generation_vijay2/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py:284\u001b[0m, in \u001b[0;36mQwen3DecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    281\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 284\u001b[0m hidden_states, self_attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn(\n\u001b[1;32m    285\u001b[0m     hidden_states\u001b[38;5;241m=\u001b[39mhidden_states,\n\u001b[1;32m    286\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m    287\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m    288\u001b[0m     past_key_value\u001b[38;5;241m=\u001b[39mpast_key_value,\n\u001b[1;32m    289\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    290\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m    291\u001b[0m     cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[1;32m    292\u001b[0m     position_embeddings\u001b[38;5;241m=\u001b[39mposition_embeddings,\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    294\u001b[0m )\n\u001b[1;32m    295\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    297\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/generation_vijay2/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/generation_vijay2/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/generation_vijay2/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py:218\u001b[0m, in \u001b[0;36mQwen3Attention.forward\u001b[0;34m(self, hidden_states, position_embeddings, attention_mask, past_key_value, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m value_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj(hidden_states)\u001b[38;5;241m.\u001b[39mview(hidden_shape)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    217\u001b[0m cos, sin \u001b[38;5;241m=\u001b[39m position_embeddings\n\u001b[0;32m--> 218\u001b[0m query_states, key_states \u001b[38;5;241m=\u001b[39m apply_rotary_pos_emb(query_states, key_states, cos, sin)\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# sin and cos are specific to RoPE models; cache_position needed for the static cache\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     cache_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msin\u001b[39m\u001b[38;5;124m\"\u001b[39m: sin, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcos\u001b[39m\u001b[38;5;124m\"\u001b[39m: cos, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache_position\u001b[39m\u001b[38;5;124m\"\u001b[39m: cache_position}\n",
      "File \u001b[0;32m~/.conda/envs/generation_vijay2/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py:123\u001b[0m, in \u001b[0;36mapply_rotary_pos_emb\u001b[0;34m(q, k, cos, sin, position_ids, unsqueeze_dim)\u001b[0m\n\u001b[1;32m    121\u001b[0m cos \u001b[38;5;241m=\u001b[39m cos\u001b[38;5;241m.\u001b[39munsqueeze(unsqueeze_dim)\n\u001b[1;32m    122\u001b[0m sin \u001b[38;5;241m=\u001b[39m sin\u001b[38;5;241m.\u001b[39munsqueeze(unsqueeze_dim)\n\u001b[0;32m--> 123\u001b[0m q_embed \u001b[38;5;241m=\u001b[39m (q \u001b[38;5;241m*\u001b[39m cos) \u001b[38;5;241m+\u001b[39m (rotate_half(q) \u001b[38;5;241m*\u001b[39m sin)\n\u001b[1;32m    124\u001b[0m k_embed \u001b[38;5;241m=\u001b[39m (k \u001b[38;5;241m*\u001b[39m cos) \u001b[38;5;241m+\u001b[39m (rotate_half(k) \u001b[38;5;241m*\u001b[39m sin)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m q_embed, k_embed\n",
      "File \u001b[0;32m~/.conda/envs/generation_vijay2/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py:98\u001b[0m, in \u001b[0;36mrotate_half\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     96\u001b[0m x1 \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, : x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     97\u001b[0m x2 \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m :]\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat((\u001b[38;5;241m-\u001b[39mx2, x1), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "system_prompt = \"You are an expert at generating synthetic data for abstract-level biomedical relation extraction.\" \n",
    "\n",
    "def split_camel_case(string):\n",
    "    result = \"\"\n",
    "    curr_start_i = 0\n",
    "    for i in range(1,len(string)):\n",
    "        if (string[i] >= 'A' and string[i] <= 'Z') or (string[i] == '_'):\n",
    "            result += string[curr_start_i:i].lower() + \" \"\n",
    "            if string[i] == '_':\n",
    "                curr_start_i = i + 1\n",
    "            else:\n",
    "                curr_start_i = i\n",
    "    result += string[curr_start_i:len(string)].lower()\n",
    "    return result\n",
    "    \n",
    "def plural(word, num):\n",
    "    if num == 1:\n",
    "        return word\n",
    "    else:\n",
    "        return word + \"s\"\n",
    "    \n",
    "def find_ent_mention(norm_ent,ent_list):\n",
    "    for ent_triple in ent_list:\n",
    "        if ent_triple[1] == norm_ent:\n",
    "            return ent_triple[2]\n",
    "    print(\"couldn't find mention for norm_ent:\",norm_ent)\n",
    "    return None\n",
    "\n",
    "def generate_user_prompt(ent_ct,rel_list):\n",
    "    # Transform given entity counter and relation list into a user prompt for the LLM\n",
    "    result = \"Generate a synthetic scientific title and abstract given the following list of mentions and relations between them.\\n\"\n",
    "    # include an example here...\n",
    "    result += \"The title and abstract (combined) should contain the following mentions (match spelling EXACTLY):\\n\"\n",
    "    for ent in ent_ct:\n",
    "        ct = ent_ct[ent]\n",
    "        result += str(ct) + \" \" + plural(\"instance\", ct) + \" of the \"  + split_camel_case(ent[0]) + \": '\" + ent[2] + \"'\\n\"\n",
    "    if len(rel_list) > 0:\n",
    "        result += \"The abstract should provide evidence for the existence of the following relationships:\\n\"\n",
    "        ent_lst = list(ent_ct)\n",
    "        for rel in rel_list:\n",
    "            rel_class = split_camel_case(rel[0])\n",
    "            rel_head = find_ent_mention(rel[1],ent_lst)\n",
    "            rel_tail = find_ent_mention(rel[2],ent_lst)\n",
    "            if (rel_head != None) and (rel_tail != None):\n",
    "                result += rel_class + \" between \" + rel_head + \" and \" + rel_tail + \"\\n\"\n",
    "    result += \"The format for the final answer is as follows:\\n\"\n",
    "    result += \"```\\n\"\n",
    "    result += \"|t|Title\\n\"\n",
    "    result += \"|a|Abstract\\n\"\n",
    "    result += \"```\\n\"\n",
    "    result += \"Here is an example following this format:\\n\"\n",
    "    result += \"```\\n\"\n",
    "    result += \"|t|\" + titles[0] + \"\\n\"\n",
    "    result += \"|a|\" + abstracts[0] +\"\\n\"\n",
    "    result += \"```\\n\"\n",
    "    result += \"Now generate your answer:\"\n",
    "    return result\n",
    "\n",
    "def generate_LLM_response(model,tokenizer,user_prompt):\n",
    "    # This is based on my own generation for Chemotimelines,\n",
    "    # which is itself based on Vijay Jain's synth_gen: https://code.rc.uab.edu/jainv/synth_gen\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ]\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "        enable_thinking = False # False for debug purposes\n",
    "    )\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "    generated_ids = model.generate(\n",
    "        **model_inputs,\n",
    "        max_new_tokens=32768, # maximum w/o yarn for Qwen3\n",
    "        do_sample = False # deterministic. ok because prompts are stochastic.\n",
    "    )\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    match = re.split(r'(.*?)</think>', response, flags=re.DOTALL) # .?* means match as few characters as possible before </think>\n",
    "    # dotall means dot matches to any char, even linebreaks\n",
    "    if len(match) > 2:\n",
    "        thought = match[1].strip()\n",
    "        cleaned_output = re.split(r'\\*Note|---', match[2].strip(), maxsplit=1)[0].strip()\n",
    "    else: # if not using reasoning, should always go down this path\n",
    "        thought = \"\"\n",
    "        cleaned_output = response\n",
    "    return cleaned_output\n",
    "\n",
    "def get_title(string):\n",
    "    first_vertical = string.index(\"|\")\n",
    "    start = first_vertical + 3\n",
    "    for i in range(start,len(string)):\n",
    "        char = string[i]\n",
    "        if char == '|':\n",
    "            return string[start:i-9]\n",
    "        \n",
    "def get_abstract(string):\n",
    "    for i in range(len(string)-2):\n",
    "        if string[i:i+3] == '|a|':\n",
    "            location = i + 3\n",
    "            return string[location:len(string)]\n",
    "        \n",
    "def get_all_spans(substring,string,increment=0):\n",
    "    result = []\n",
    "    keep_going = True\n",
    "    start_search = 0 # index at which to start the search\n",
    "    while keep_going:\n",
    "        try:\n",
    "            start_i = string.index(substring,start_search)\n",
    "            end_i = start_i + len(substring)\n",
    "            result.append((start_i+increment,end_i+increment))\n",
    "            start_search = end_i\n",
    "        except ValueError:\n",
    "            # didn't find it\n",
    "            keep_going = False\n",
    "    return result\n",
    "\n",
    "def parse_llm_response(llm_response, ent_ct, rel_list):\n",
    "    # Want to generate something in the PubTator format.\n",
    "    # Zeroth, generate a fake pmid to use\n",
    "    pmid = \"\"\n",
    "    for i in range(8):\n",
    "        rand_num = np.random.choice(10,1)[0]\n",
    "        pmid += str(rand_num)\n",
    "    # First, get the part we care about: between ``` and ```\n",
    "    # Asked ChatGPT how to perform the regex: https://chatgpt.com/share/69289dba-3978-800f-915b-fa07727c9c01\n",
    "    important_txt = re.search(r\"```(.*?)```\", llm_response, re.DOTALL).group(1).strip()\n",
    "    title = get_title(important_txt).replace('\\n',' ') # easier if all on one line\n",
    "    title_len = len(title)\n",
    "    #print(\"title length:\",title_len)\n",
    "    abstract = get_abstract(important_txt).replace('\\n',' ') # easier if all on one line\n",
    "    # This inlcudes both the title and the abstract :). Now, need to find the exact matches of each of the entities\n",
    "    #print(\"pmid:\",pmid)\n",
    "    #print(\"important text:\",important_txt)\n",
    "    #print(\"title:\",title)\n",
    "    #print(\"abstract:\",abstract)\n",
    "    exact_matches_list = [] # list of tuple: (start, end, mention, class, norm_ent)\n",
    "    llm_ent_ct = Counter() # to see how faithful llm is to instructions (compare to ent_ct)\n",
    "    for ent in ent_ct:\n",
    "        # check title and abstract\n",
    "        title_spans = get_all_spans(ent[2],title)\n",
    "        abstract_spans = get_all_spans(ent[2],abstract,title_len+1)\n",
    "        all_spans = title_spans + abstract_spans\n",
    "        num_spans = len(all_spans)\n",
    "        llm_ent_ct[ent] = num_spans\n",
    "        for span in all_spans:\n",
    "            exact_matches_list.append((str(span[0]),str(span[1]),ent[2],ent[0],ent[1]))\n",
    "    exact_matches_list.sort(key=(lambda x: int(x[0])))\n",
    "    # Ready to create output pubtator style\n",
    "    result = pmid + \"|t|\" + title + \"\\n\" + pmid + \"|a|\" + abstract + '\\n'\n",
    "    for match in exact_matches_list:\n",
    "        result += pmid + '\\t'\n",
    "        for i in range(len(match)):\n",
    "            result += match[i]\n",
    "            if i < len(match) - 1:\n",
    "                result += '\\t'\n",
    "        result += '\\n'\n",
    "    for rel in rel_list:\n",
    "        result += pmid + '\\t'\n",
    "        for i in range(len(rel)):\n",
    "            result += rel[i] + '\\t'\n",
    "        result += \"Novel\\n\"\n",
    "    # Return both the result and the counter\n",
    "    return result, llm_ent_ct\n",
    "     \n",
    "def avg_per_change(ground_truth_ct,llm_ct):\n",
    "    def per_change(key):\n",
    "        gt_ent = ground_truth_ct[key]\n",
    "        llm_ent = llm_ct[key]\n",
    "        return (abs(llm_ent-gt_ent)/gt_ent) * 100\n",
    "    gt_keys = ground_truth_ct.keys()\n",
    "    num_keys = len(gt_keys)\n",
    "    return sum(list(map(per_change,gt_keys)))/num_keys\n",
    "    \n",
    "# Main generation loop\n",
    "output_file_name = \"data/SynthTrain.PubTator\"\n",
    "output_faithfullness_csv = \"data/synth_faithfullness.csv\"\n",
    "with open(output_faithfullness_csv,\"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"ground_truth_counter\",\"llm_generation_counter\",\"average_percent_change\"])\n",
    "num_synthetic = 500 # maximum number to generate\n",
    "for i in range(1,num_synthetic+1):\n",
    "    print(\"---------------------------------\")\n",
    "    synthetic_ents, synthetic_rels = get_synthetic_ents_and_rels()\n",
    "    print(\"generated synthetic entities and relations\")\n",
    "    u_prompt = generate_user_prompt(synthetic_ents, synthetic_rels)\n",
    "    print(\"generated user prompt\")\n",
    "    response = generate_LLM_response(model,tokenizer,u_prompt)\n",
    "    print(\"generated response\")\n",
    "    parsed_response, llm_ent_ct = parse_llm_response(response,synthetic_ents,synthetic_rels)\n",
    "    print(\"parsed response\")\n",
    "    with open(output_file_name, \"a\") as f:\n",
    "        f.write(parsed_response+\"\\n\")\n",
    "    print(\"output to pubtator file\")\n",
    "    with open(output_faithfullness_csv,\"a\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([str(synthetic_ents),str(llm_ent_ct),avg_per_change(synthetic_ents,llm_ent_ct)])\n",
    "    print(\"output to csv file\")\n",
    "    print(\"Completed abstract\",i,\"of\",num_synthetic)\n",
    "print(\"done\")\n",
    "    \n",
    "        \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4955a14-5f9a-482b-9d6d-a8b111789fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test options: [0, 1, 2, 3, 4, 5]\n",
      "test p: [0.0125, 0.235, 0.3575, 0.3225, 0.0675, 0.005]\n",
      "5\n",
      "True\n",
      "{(1, 2): 3}\n",
      "Counter({('SequenceVariant', 'c|SUB|G|1092+1|A', 'c.1092 +1G>A'): 8, ('GeneOrGeneProduct', '185', 'angiotensin II receptor type 1'): 6, ('OrganismTaxon', '9544', 'rhesus monkeys'): 5, ('ChemicalEntity', 'C009591', 'TTC'): 4, ('SequenceVariant', 'c|DEL|1952|9', 'nine-nucleotide deletion starting at position 1952'): 4, ('OrganismTaxon', '9031', 'chick'): 4, ('GeneOrGeneProduct', '20779', 'Src family kinases'): 4, ('OrganismTaxon', '9940', 'sheep'): 2})\n",
      "[('Bind', '185', 'C009591'), ('Positive_Correlation', '20779', '185'), ('Bind', '20779', 'C009591'), ('Positive_Correlation', '185', '20779'), ('Bind', '20779', '185'), ('Bind', '185', '20779')]\n",
      "disease or phenotypic feature\n",
      "positive  correlation\n",
      "Generate a synthetic scientific title and abstract given the following list of mentions and relations between them.\n",
      "The title and abstract (combined) should contain the following mentions (match spelling EXACTLY):\n",
      "6 instances of the gene or gene product: 'angiotensin II receptor type 1'\n",
      "2 instances of the organism taxon: 'sheep'\n",
      "4 instances of the chemical entity: 'TTC'\n",
      "4 instances of the sequence variant: 'nine-nucleotide deletion starting at position 1952'\n",
      "5 instances of the organism taxon: 'rhesus monkeys'\n",
      "4 instances of the organism taxon: 'chick'\n",
      "4 instances of the gene or gene product: 'Src family kinases'\n",
      "8 instances of the sequence variant: 'c.1092 +1G>A'\n",
      "The abstract should provide evidence for the existence of the following relationships:\n",
      "bind between angiotensin II receptor type 1 and TTC\n",
      "positive  correlation between Src family kinases and angiotensin II receptor type 1\n",
      "bind between Src family kinases and TTC\n",
      "positive  correlation between angiotensin II receptor type 1 and Src family kinases\n",
      "bind between Src family kinases and angiotensin II receptor type 1\n",
      "bind between angiotensin II receptor type 1 and Src family kinases\n",
      "The format for the final answer is as follows:\n",
      "```\n",
      "|t|Title\n",
      "|a|Abstract\n",
      "```\n",
      "Here is an example following this format:\n",
      "```\n",
      "|t|Hepatocyte nuclear factor-6: associations between genetic variability and type II diabetes and between genetic variability and estimates of insulin secretion.\n",
      "|a|The transcription factor hepatocyte nuclear factor (HNF)-6 is an upstream regulator of several genes involved in the pathogenesis of maturity-onset diabetes of the young. We therefore tested the hypothesis that variability in the HNF-6 gene is associated with subsets of Type II (non-insulin-dependent) diabetes mellitus and estimates of insulin secretion in glucose tolerant subjects.   We cloned the coding region as well as the intron-exon boundaries of the HNF-6 gene. We then examined them on genomic DNA in six MODY probands without mutations in the MODY1, MODY3 and MODY4 genes and in 54 patients with late-onset Type II diabetes by combined single strand conformational polymorphism-heteroduplex analysis followed by direct sequencing of identified variants. An identified missense variant was examined in association studies and genotype-phenotype studies.   We identified two silent and one missense (Pro75 Ala) variant. In an association study the allelic frequency of the Pro75Ala polymorphism was 3.2% (95% confidence interval, 1.9-4.5) in 330 patients with Type II diabetes mellitus compared with 4.2% (2.4-6.0) in 238 age-matched glucose tolerant control subjects. Moreover, in studies of 238 middle-aged glucose tolerant subjects, of 226 glucose tolerant offspring of Type II diabetic patients and of 367 young healthy subjects, the carriers of the polymorphism did not differ from non-carriers in glucose induced serum insulin or C-peptide responses.   Mutations in the coding region of the HNF-6 gene are not associated with Type II diabetes or with changes in insulin responses to glucose among the Caucasians examined.\n",
      "```\n",
      "Now generate your answer:\n",
      "Hepatocyte nuclear factor-6\n",
      "span test: [(298, 301), (345, 348), (359, 362), (376, 379), (384, 387), (411, 414), (583, 586), (612, 615), (642, 645), (661, 664), (675, 678), (737, 740), (1140, 1143), (1165, 1168), (1530, 1533), (1546, 1549), (1668, 1671), (1689, 1692), (1799, 1802)]\n",
      "title length: 158\n",
      "parse result\n",
      "\n",
      "71383849|t|Hepatocyte nuclear factor-6: associations between genetic variability and type II diabetes and between genetic variability and estimates of insulin secretion.\n",
      "71383849|a|The transcription factor hepatocyte nuclear factor (HNF)-6 is an upstream regulator of several genes involved in the pathogenesis of maturity-onset diabetes of the young. We therefore tested the hypothesis that variability in the HNF-6 gene is associated with subsets of Type II (non-insulin-dependent) diabetes mellitus and estimates of insulin secretion in glucose tolerant subjects.   We cloned the coding region as well as the intron-exon boundaries of the HNF-6 gene. We then examined them on genomic DNA in six MODY probands without mutations in the MODY1, MODY3 and MODY4 genes and in 54 patients with late-onset Type II diabetes by combined single strand conformational polymorphism-heteroduplex analysis followed by direct sequencing of identified variants. An identified missense variant was examined in association studies and genotype-phenotype studies.   We identified two silent and one missense (Pro75 Ala) variant. In an association study the allelic frequency of the Pro75Ala polymorphism was 3.2% (95% confidence interval, 1.9-4.5) in 330 patients with Type II diabetes mellitus compared with 4.2% (2.4-6.0) in 238 age-matched glucose tolerant control subjects. Moreover, in studies of 238 middle-aged glucose tolerant subjects, of 226 glucose tolerant offspring of Type II diabetic patients and of 367 young healthy subjects, the carriers of the polymorphism did not differ from non-carriers in glucose induced serum insulin or C-peptide responses.   Mutations in the coding region of the HNF-6 gene are not associated with Type II diabetes or with changes in insulin responses to glucose among the Caucasians examined.\n",
      "71383849\t0\t27\tHepatocyte nuclear factor-6\tGeneOrGeneProduct\t3175\n",
      "71383849\t518\t525\tglucose\tChemicalEntity\tD005947\n",
      "71383849\t1304\t1311\tglucose\tChemicalEntity\tD005947\n",
      "71383849\t1379\t1386\tglucose\tChemicalEntity\tD005947\n",
      "71383849\t1413\t1420\tglucose\tChemicalEntity\tD005947\n",
      "71383849\t1573\t1580\tglucose\tChemicalEntity\tD005947\n",
      "71383849\t1759\t1766\tglucose\tChemicalEntity\tD005947\n",
      "71383849\tAssociation\t3175\tD003924\tNovel\n",
      "71383849\tPositive_Correlation\tD005947\t3630\tNovel\n",
      "\n",
      "\n",
      "result ct\n",
      "Counter({('ChemicalEntity', 'D005947', 'glucose'): 6, ('GeneOrGeneProduct', '3175', 'Hepatocyte nuclear factor-6'): 1})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "np.random.choice([1,2,4,8,],1,p=[0.4,0.3,0.2,0.1])[0]\n",
    "test_lst = [5,5,2,2,2,3]\n",
    "test_options, test_p = get_dist(num_unique_rels_per_doc)\n",
    "print(\"test options:\",test_options)\n",
    "print(\"test p:\",test_p)\n",
    "test_set = {2,3,4,5,6}\n",
    "print(np.random.choice(list(test_set),1)[0])\n",
    "print((1,2) == (1,2,3)[:2])\n",
    "test_dict = dict()\n",
    "test_dict[(1,2)] = 3\n",
    "print(test_dict)\n",
    "selected_ents, selected_rels = get_synthetic_ents_and_rels()\n",
    "print(selected_ents)\n",
    "print(selected_rels)\n",
    "print(split_camel_case(\"DiseaseOrPhenotypicFeature\"))\n",
    "print(split_camel_case(\"Positive_Correlation\"))\n",
    "up = generate_user_prompt(selected_ents, selected_rels)\n",
    "print(up)\n",
    "print(titles[0][0:27])\n",
    "title_len = len(titles[0])\n",
    "#print(title_len)\n",
    "#print(abstracts[0][(732-title_len-1):(737-title_len-1)])\n",
    "#print(generate_LLM_response(model,tokenizer,up))\n",
    "\n",
    "sample_txt = \"\"\"```\n",
    "10491763|t|Hepatocyte nuclear factor-6: associations between genetic variability and type II diabetes and between genetic variability and estimates of insulin secretion.\n",
    "10491763|a|The transcription factor hepatocyte nuclear factor (HNF)-6 is an upstream regulator of several genes involved in the pathogenesis of maturity-onset diabetes of the young. We therefore tested the hypothesis that variability in the HNF-6 gene is associated with subsets of Type II (non-insulin-dependent) diabetes mellitus and estimates of insulin secretion in glucose tolerant subjects.   We cloned the coding region as well as the intron-exon boundaries of the HNF-6 gene. We then examined them on genomic DNA in six MODY probands without mutations in the MODY1, MODY3 and MODY4 genes and in 54 patients with late-onset Type II diabetes by combined single strand conformational polymorphism-heteroduplex analysis followed by direct sequencing of identified variants. An identified missense variant was examined in association studies and genotype-phenotype studies.   We identified two silent and one missense (Pro75 Ala) variant. In an association study the allelic frequency of the Pro75Ala polymorphism was 3.2% (95% confidence interval, 1.9-4.5) in 330 patients with Type II diabetes mellitus compared with 4.2% (2.4-6.0) in 238 age-matched glucose tolerant control subjects. Moreover, in studies of 238 middle-aged glucose tolerant subjects, of 226 glucose tolerant offspring of Type II diabetic patients and of 367 young healthy subjects, the carriers of the polymorphism did not differ from non-carriers in glucose induced serum insulin or C-peptide responses.   Mutations in the coding region of the HNF-6 gene are not associated with Type II diabetes or with changes in insulin responses to glucose among the Caucasians examined.\n",
    "```\"\"\"\n",
    "print(\"span test:\",get_all_spans(\"the\",sample_txt))\n",
    "test_counter = Counter()\n",
    "test_counter[(\"GeneOrGeneProduct\",str(3175),\"Hepatocyte nuclear factor-6\")] += 1\n",
    "test_counter[(\"ChemicalEntity\",\"D005947\",\"glucose\")] += 1\n",
    "test_rels = [(\"Association\",\"3175\",\"D003924\"),(\"Positive_Correlation\",\"D005947\",\"3630\")]\n",
    "parse_result, result_ct = parse_llm_response(sample_txt,test_counter,test_rels)\n",
    "print(\"parse result\\n\")\n",
    "print(parse_result)\n",
    "print(\"\\nresult ct\")\n",
    "print(result_ct)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a473880-03dd-4a09-8647-5f32a6d97ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5441bea-6c9d-4e3e-b48e-787526ce996f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (generation_vijay2)",
   "language": "python",
   "name": "generation_vijay2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
