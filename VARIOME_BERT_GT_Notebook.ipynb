{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT-GT for BioRED Relation Extraction\n",
    "\n",
    "This notebook implements **BERT-GT (BERT with Graph Transformer)** - the official model from the BioRED paper.\n",
    "\n",
    "## What is BERT-GT?\n",
    "\n",
    "BERT-GT improves relation extraction by:\n",
    "- **Graph Transformer layers** that model entity interactions\n",
    "- **Document-level reasoning** for cross-sentence relations\n",
    "- **Entity-aware attention** focusing on entity pairs\n",
    "\n",
    "**Reference**: https://github.com/ncbi/bert_gt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
      "Collecting torch==2.6.0\n",
      "  Using cached https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp39-cp39-linux_x86_64.whl.metadata (28 kB)\n",
      "Collecting torchvision==0.21.0\n",
      "  Using cached https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp39-cp39-linux_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting torchaudio==2.6.0\n",
      "  Using cached https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp39-cp39-linux_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: filelock in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (from torch==2.6.0) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (from torch==2.6.0) (4.15.0)\n",
      "Requirement already satisfied: networkx in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (from torch==2.6.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (from torch==2.6.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (from torch==2.6.0) (2025.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (from torch==2.6.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (from torch==2.6.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (from torch==2.6.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (from torch==2.6.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (from torch==2.6.0) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (from torch==2.6.0) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (from torch==2.6.0) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (from torch==2.6.0) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (from torch==2.6.0) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (from torch==2.6.0) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (from torch==2.6.0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (from torch==2.6.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (from torch==2.6.0) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (from torch==2.6.0) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (from torch==2.6.0) (1.13.1)\n",
      "Requirement already satisfied: numpy in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (from torchvision==0.21.0) (1.26.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (from torchvision==0.21.0) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (from sympy==1.13.1->torch==2.6.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (from jinja2->torch==2.6.0) (2.1.5)\n",
      "Using cached https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp39-cp39-linux_x86_64.whl (768.4 MB)\n",
      "Using cached https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp39-cp39-linux_x86_64.whl (7.3 MB)\n",
      "Using cached https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp39-cp39-linux_x86_64.whl (3.4 MB)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [torchaudio]3\u001b[0m [torchaudio]]\n",
      "\u001b[1A\u001b[2KSuccessfully installed torch-2.6.0+cu124 torchaudio-2.6.0+cu124 torchvision-0.21.0+cu124\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: torch in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (2.6.0+cu124)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: filelock in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (from transformers) (3.19.1)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (from transformers) (1.26.3)\n",
      "Collecting packaging>=20.0 (from transformers)\n",
      "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Downloading pyyaml-6.0.3-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2025.11.3-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (40 kB)\n",
      "Collecting requests (from transformers)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: networkx in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/crivelli/.conda/envs/bert-gt/lib/python3.9/site-packages (from jinja2->torch) (2.1.5)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->transformers)\n",
      "  Downloading charset_normalizer-3.4.4-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->transformers)\n",
      "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers)\n",
      "  Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "Downloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.6.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Downloading packaging-25.0-py3-none-any.whl (66 kB)\n",
      "Downloading pyyaml-6.0.3-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (750 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.8/750.8 kB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2025.11.3-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (781 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.9/781.9 kB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n",
      "Downloading scipy-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
      "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: urllib3, tqdm, threadpoolctl, scipy, safetensors, regex, pyyaml, packaging, joblib, idna, hf-xet, charset_normalizer, certifi, scikit-learn, requests, huggingface-hub, tokenizers, transformers\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/18\u001b[0m [transformers][0m [transformers]ub]\n",
      "\u001b[1A\u001b[2KSuccessfully installed certifi-2025.11.12 charset_normalizer-3.4.4 hf-xet-1.2.0 huggingface-hub-0.36.0 idna-3.11 joblib-1.5.2 packaging-25.0 pyyaml-6.0.3 regex-2025.11.3 requests-2.32.5 safetensors-0.7.0 scikit-learn-1.6.1 scipy-1.13.1 threadpoolctl-3.6.0 tokenizers-0.22.1 tqdm-4.67.1 transformers-4.57.3 urllib3-2.5.0\n"
     ]
    }
   ],
   "source": [
    "# Install required packages (run once)\n",
    "!pip install transformers torch scikit-learn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Dec  5 07:28:46 2025       \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\r\n",
      "|-----------------------------------------+------------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                        |               MIG M. |\r\n",
      "|=========================================+========================+======================|\r\n",
      "|   0  Tesla P100-PCIE-16GB           On  |   00000000:05:00.0 Off |                    0 |\r\n",
      "| N/A   31C    P0             25W /  250W |       0MiB /  16384MiB |      0%      Default |\r\n",
      "|                                         |                        |                  N/A |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                              |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\r\n",
      "|        ID   ID                                                               Usage      |\r\n",
      "|=========================================================================================|\r\n",
      "|  No running processes found                                                             |\r\n",
      "+-----------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.0.1\n",
      "CUDA available: False\n",
      "CUDA version in PyTorch: None\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version in PyTorch: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Number of GPUs available: 0\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of GPUs available: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU index in use: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mcurrent_device()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mget_device_name(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/share/apps/rc/software/Anaconda3/2023.07-2/lib/python3.11/site-packages/torch/cuda/__init__.py:674\u001b[0m, in \u001b[0;36mcurrent_device\u001b[0;34m()\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcurrent_device\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m    673\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the index of a currently selected device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     _lazy_init()\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_cuda_getDevice()\n",
      "File \u001b[0;32m/share/apps/rc/software/Anaconda3/2023.07-2/lib/python3.11/site-packages/torch/cuda/__init__.py:239\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    236\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 239\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModel, AutoTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Number of GPUs available: {torch.cuda.device_count()}\")\n",
    "print(f\"GPU index in use: {torch.cuda.current_device()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Graph Transformer Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ GraphTransformerLayer defined\n"
     ]
    }
   ],
   "source": [
    "class GraphTransformerLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Graph Transformer Layer for modeling entity interactions.\n",
    "    \n",
    "    This layer treats entities as nodes in a graph and uses\n",
    "    graph attention to model their relationships.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_size, num_heads=4, dropout=0.1):\n",
    "        super(GraphTransformerLayer, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = hidden_size // num_heads\n",
    "        \n",
    "        assert hidden_size % num_heads == 0, \"hidden_size must be divisible by num_heads\"\n",
    "        \n",
    "        # Multi-head attention for graph\n",
    "        self.query = nn.Linear(hidden_size, hidden_size)\n",
    "        self.key = nn.Linear(hidden_size, hidden_size)\n",
    "        self.value = nn.Linear(hidden_size, hidden_size)\n",
    "        self.out_proj = nn.Linear(hidden_size, hidden_size)\n",
    "        \n",
    "        # Layer normalization\n",
    "        self.layer_norm1 = nn.LayerNorm(hidden_size)\n",
    "        self.layer_norm2 = nn.LayerNorm(hidden_size)\n",
    "        \n",
    "        # Feed-forward network\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_size * 4, hidden_size),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, entity_reprs, adjacency_matrix=None):\n",
    "        \"\"\"\n",
    "        Apply graph transformer layer.\n",
    "        \n",
    "        Args:\n",
    "            entity_reprs: [batch_size, num_entities, hidden_size]\n",
    "            adjacency_matrix: [batch_size, num_entities, num_entities] (optional)\n",
    "        \n",
    "        Returns:\n",
    "            Updated entity representations [batch_size, num_entities, hidden_size]\n",
    "        \"\"\"\n",
    "        batch_size, num_entities, hidden_size = entity_reprs.size()\n",
    "        \n",
    "        # Multi-head self-attention on graph\n",
    "        Q = self.query(entity_reprs).view(batch_size, num_entities, self.num_heads, self.head_dim)\n",
    "        K = self.key(entity_reprs).view(batch_size, num_entities, self.num_heads, self.head_dim)\n",
    "        V = self.value(entity_reprs).view(batch_size, num_entities, self.num_heads, self.head_dim)\n",
    "        \n",
    "        Q = Q.transpose(1, 2)  # [batch_size, num_heads, num_entities, head_dim]\n",
    "        K = K.transpose(1, 2)\n",
    "        V = V.transpose(1, 2)\n",
    "        \n",
    "        # Compute attention scores\n",
    "        attention_scores = torch.matmul(Q, K.transpose(-2, -1)) / (self.head_dim ** 0.5)\n",
    "        \n",
    "        # Apply adjacency matrix if provided (mask non-neighbors)\n",
    "        if adjacency_matrix is not None:\n",
    "            adjacency_matrix = adjacency_matrix.unsqueeze(1)  # [batch_size, 1, num_entities, num_entities]\n",
    "            attention_scores = attention_scores.masked_fill(adjacency_matrix == 0, -1e9)\n",
    "        \n",
    "        # Attention weights\n",
    "        attention_probs = F.softmax(attention_scores, dim=-1)\n",
    "        attention_probs = self.dropout(attention_probs)\n",
    "        \n",
    "        # Apply attention to values\n",
    "        context = torch.matmul(attention_probs, V)  # [batch_size, num_heads, num_entities, head_dim]\n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, num_entities, hidden_size)\n",
    "        \n",
    "        # Output projection + residual\n",
    "        output = self.out_proj(context)\n",
    "        output = self.dropout(output)\n",
    "        entity_reprs = self.layer_norm1(entity_reprs + output)\n",
    "        \n",
    "        # Feed-forward + residual\n",
    "        ffn_output = self.ffn(entity_reprs)\n",
    "        entity_reprs = self.layer_norm2(entity_reprs + ffn_output)\n",
    "        \n",
    "        return entity_reprs\n",
    "\n",
    "print(\"✓ GraphTransformerLayer defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. BERT-GT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ BERTGTModel defined\n"
     ]
    }
   ],
   "source": [
    "class BERTGTModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Complete BERT-GT model for document-level relation extraction.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name='dmis-lab/biobert-v1.1',\n",
    "        num_relations=4,\n",
    "        num_graph_layers=2,\n",
    "        num_attention_heads=4,\n",
    "        max_entities=20,\n",
    "        dropout=0.1\n",
    "    ):\n",
    "        super(BERTGTModel, self).__init__()\n",
    "        \n",
    "        # BioBERT encoder\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.hidden_size = self.bert.config.hidden_size\n",
    "        self.max_entities = max_entities\n",
    "        \n",
    "        # Entity representation layer\n",
    "        self.entity_projection = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        \n",
    "        # Graph Transformer layers\n",
    "        self.graph_layers = nn.ModuleList([\n",
    "            GraphTransformerLayer(\n",
    "                self.hidden_size,\n",
    "                num_heads=num_attention_heads,\n",
    "                dropout=dropout\n",
    "            )\n",
    "            for _ in range(num_graph_layers)\n",
    "        ])\n",
    "        \n",
    "        # Entity pair combination: [e1, e2, e1*e2]\n",
    "        self.pair_projection = nn.Linear(self.hidden_size * 3, self.hidden_size)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Relation classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.hidden_size, self.hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(self.hidden_size, num_relations)\n",
    "        )\n",
    "    \n",
    "    def extract_entity_representations(self, sequence_output, entity_positions, batch_size):\n",
    "        \"\"\"\n",
    "        Extract entity representations from BERT output using average pooling.\n",
    "        \"\"\"\n",
    "        all_entity_reprs = []\n",
    "        entity_masks = []\n",
    "        \n",
    "        for b in range(batch_size):\n",
    "            batch_entities = entity_positions[b]\n",
    "            entity_reprs = []\n",
    "            \n",
    "            for entity in batch_entities[:self.max_entities]:\n",
    "                start = entity['start']\n",
    "                end = entity['end'] + 1  # Inclusive end\n",
    "                \n",
    "                # Average pooling over entity tokens\n",
    "                entity_tokens = sequence_output[b, start:end, :]\n",
    "                if entity_tokens.size(0) > 0:\n",
    "                    entity_repr = entity_tokens.mean(dim=0)\n",
    "                else:\n",
    "                    entity_repr = torch.zeros(self.hidden_size, device=sequence_output.device)\n",
    "                \n",
    "                entity_reprs.append(entity_repr)\n",
    "            \n",
    "            # Pad to max_entities\n",
    "            num_entities = len(entity_reprs)\n",
    "            mask = [1] * num_entities + [0] * (self.max_entities - num_entities)\n",
    "            \n",
    "            while len(entity_reprs) < self.max_entities:\n",
    "                entity_reprs.append(torch.zeros(self.hidden_size, device=sequence_output.device))\n",
    "            \n",
    "            all_entity_reprs.append(torch.stack(entity_reprs[:self.max_entities]))\n",
    "            entity_masks.append(mask)\n",
    "        \n",
    "        entity_reprs = torch.stack(all_entity_reprs)  # [batch_size, max_entities, hidden_size]\n",
    "        entity_masks = torch.tensor(entity_masks, device=sequence_output.device)\n",
    "        \n",
    "        return entity_reprs, entity_masks\n",
    "    \n",
    "    def build_adjacency_matrix(self, entity_positions, batch_size):\n",
    "        \"\"\"\n",
    "        Build adjacency matrix for entity graph.\n",
    "        Uses fully connected graph (all entities can attend to each other).\n",
    "        \"\"\"\n",
    "        adjacency_matrices = []\n",
    "        \n",
    "        for b in range(batch_size):\n",
    "            num_entities = min(len(entity_positions[b]), self.max_entities)\n",
    "            \n",
    "            # Fully connected graph\n",
    "            adj_matrix = torch.zeros(self.max_entities, self.max_entities)\n",
    "            adj_matrix[:num_entities, :num_entities] = 1\n",
    "            \n",
    "            adjacency_matrices.append(adj_matrix)\n",
    "        \n",
    "        return torch.stack(adjacency_matrices).to(self.bert.device)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, entity1_start, entity1_end, \n",
    "                entity2_start, entity2_end, entities, labels=None):\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "        \"\"\"\n",
    "        batch_size = input_ids.size(0)\n",
    "        \n",
    "        # Get BERT representations\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        \n",
    "        sequence_output = outputs.last_hidden_state  # [batch_size, seq_length, hidden_size]\n",
    "        \n",
    "        # Extract entity representations\n",
    "        entity_reprs, entity_mask = self.extract_entity_representations(\n",
    "            sequence_output, entities, batch_size\n",
    "        )\n",
    "        \n",
    "        # Project entity representations\n",
    "        entity_reprs = self.entity_projection(entity_reprs)\n",
    "        entity_reprs = self.dropout(entity_reprs)\n",
    "        \n",
    "        # Build adjacency matrix\n",
    "        adjacency_matrix = self.build_adjacency_matrix(entities, batch_size)\n",
    "        \n",
    "        # Apply Graph Transformer layers\n",
    "        for graph_layer in self.graph_layers:\n",
    "            entity_reprs = graph_layer(entity_reprs, adjacency_matrix)\n",
    "        \n",
    "        # Get target entity pair representations\n",
    "        pair_reprs = []\n",
    "        for b in range(batch_size):\n",
    "            # Find target entities\n",
    "            target_ent1_start = entity1_start[b]\n",
    "            target_ent2_start = entity2_start[b]\n",
    "            \n",
    "            ent1_idx = None\n",
    "            ent2_idx = None\n",
    "            for i, entity in enumerate(entities[b][:self.max_entities]):\n",
    "                if entity['start'] == target_ent1_start:\n",
    "                    ent1_idx = i\n",
    "                if entity['start'] == target_ent2_start:\n",
    "                    ent2_idx = i\n",
    "            \n",
    "            # Get representations\n",
    "            if ent1_idx is not None and ent2_idx is not None:\n",
    "                e1_repr = entity_reprs[b, ent1_idx]\n",
    "                e2_repr = entity_reprs[b, ent2_idx]\n",
    "            else:\n",
    "                e1_repr = torch.zeros(self.hidden_size, device=entity_reprs.device)\n",
    "                e2_repr = torch.zeros(self.hidden_size, device=entity_reprs.device)\n",
    "            \n",
    "            # Combine: [e1, e2, e1*e2]\n",
    "            pair_repr = torch.cat([e1_repr, e2_repr, e1_repr * e2_repr], dim=0)\n",
    "            pair_reprs.append(pair_repr)\n",
    "        \n",
    "        pair_reprs = torch.stack(pair_reprs)  # [batch_size, hidden_size * 3]\n",
    "        \n",
    "        # Project and classify\n",
    "        pair_repr = self.pair_projection(pair_reprs)\n",
    "        pair_repr = self.dropout(pair_repr)\n",
    "        logits = self.classifier(pair_repr)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits, labels)\n",
    "        \n",
    "        return {'loss': loss, 'logits': logits} if loss is not None else {'logits': logits}\n",
    "\n",
    "print(\"✓ BERTGTModel defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Fixed BioREDToBERTGTConverter defined\n"
     ]
    }
   ],
   "source": [
    "class BioREDToBERTGTConverter:\n",
    "    \"\"\"\n",
    "    Converts BioRED documents to BERT-GT format.\n",
    "    FIXED VERSION - handles various entity type names.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, tokenizer, max_seq_length=512):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self._debug_mode = True  # Set to False after testing\n",
    "    \n",
    "    def convert_documents(self, documents):\n",
    "        \"\"\"\n",
    "        Convert BioRED documents to BERT-GT format.\n",
    "        \"\"\"\n",
    "        bert_gt_examples = []\n",
    "        \n",
    "        for doc_idx, doc in enumerate(tqdm(documents, desc=\"Converting to BERT-GT format\")):\n",
    "            # Get text and entities\n",
    "            text = doc['text']\n",
    "            entities = doc['entities']\n",
    "            relations = doc['relations']\n",
    "            \n",
    "            if self._debug_mode and doc_idx == 0:\n",
    "                print(f\"\\n  DEBUG: First document\")\n",
    "                print(f\"    Text: '{text[:100]}...'\")\n",
    "                print(f\"    Entities: {len(entities)}\")\n",
    "                print(f\"    Relations: {len(relations)}\")\n",
    "            \n",
    "            # Tokenize\n",
    "            encoding = self.tokenizer(\n",
    "                text,\n",
    "                max_length=self.max_seq_length,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_offsets_mapping=True\n",
    "            )\n",
    "            \n",
    "            # Map entities to token positions\n",
    "            token_to_char = encoding['offset_mapping']\n",
    "            entity_token_positions = []\n",
    "            \n",
    "            for ent in entities:\n",
    "                char_start = ent['start']\n",
    "                char_end = ent['end']\n",
    "                \n",
    "                # Find token positions\n",
    "                token_start = None\n",
    "                token_end = None\n",
    "                \n",
    "                for i, (t_start, t_end) in enumerate(token_to_char):\n",
    "                    if t_start <= char_start < t_end and token_start is None:\n",
    "                        token_start = i\n",
    "                    if t_start < char_end <= t_end:\n",
    "                        token_end = i\n",
    "                        break\n",
    "                \n",
    "                # Also accept if token overlaps with entity\n",
    "                if token_start is None or token_end is None:\n",
    "                    for i, (t_start, t_end) in enumerate(token_to_char):\n",
    "                        # Check overlap\n",
    "                        if t_start <= char_start < t_end:\n",
    "                            token_start = i\n",
    "                        if t_start <= char_end <= t_end or (t_start < char_end and char_end <= t_end):\n",
    "                            token_end = i\n",
    "                            break\n",
    "                \n",
    "                if token_start is not None and token_end is not None:\n",
    "                    entity_token_positions.append({\n",
    "                        'id': ent['id'],\n",
    "                        'type': ent['type'],\n",
    "                        'start': token_start,\n",
    "                        'end': token_end,\n",
    "                        'text': ent['text']\n",
    "                    })\n",
    "            \n",
    "            if self._debug_mode and doc_idx == 0:\n",
    "                print(f\"    Mapped entities: {len(entity_token_positions)}/{len(entities)}\")\n",
    "                if len(entity_token_positions) > 0:\n",
    "                    print(f\"    First mapped entity: {entity_token_positions[0]}\")\n",
    "            \n",
    "            # Create entity pairs\n",
    "            pairs_created = 0\n",
    "            for i, ent1 in enumerate(entity_token_positions):\n",
    "                for ent2 in entity_token_positions[i+1:]:\n",
    "                    # Check if valid pair\n",
    "                    if not self._is_valid_pair(ent1['type'], ent2['type']):\n",
    "                        continue\n",
    "                    \n",
    "                    # Find relation label\n",
    "                    relation_label = self._find_relation(ent1['id'], ent2['id'], relations)\n",
    "                    \n",
    "                    # Create example\n",
    "                    example = {\n",
    "                        'input_ids': encoding['input_ids'],\n",
    "                        'attention_mask': encoding['attention_mask'],\n",
    "                        'entity1_start': ent1['start'],\n",
    "                        'entity1_end': ent1['end'],\n",
    "                        'entity1_type': ent1['type'],\n",
    "                        'entity2_start': ent2['start'],\n",
    "                        'entity2_end': ent2['end'],\n",
    "                        'entity2_type': ent2['type'],\n",
    "                        'entities': entity_token_positions,\n",
    "                        'label': relation_label,\n",
    "                        'pmid': doc['pmid']\n",
    "                    }\n",
    "                    \n",
    "                    bert_gt_examples.append(example)\n",
    "                    pairs_created += 1\n",
    "            \n",
    "            if self._debug_mode and doc_idx == 0:\n",
    "                print(f\"    Pairs created: {pairs_created}\")\n",
    "        \n",
    "        # Turn off debug after first document\n",
    "        self._debug_mode = False\n",
    "        \n",
    "        return bert_gt_examples\n",
    "    \n",
    "    def _is_valid_pair(self, type1, type2):\n",
    "        \"\"\"Check if entity pair is valid for RE.\"\"\"\n",
    "        \n",
    "        # Normalize entity types\n",
    "        def normalize_type(t):\n",
    "            t = t.lower()\n",
    "            # Map various type names to standard names\n",
    "            if 'gene' in t or 'protein' in t:\n",
    "                return 'gene'\n",
    "            if 'disease' in t or 'phenotype' in t:\n",
    "                return 'disease'\n",
    "            if 'variant' in t or 'mutation' in t or 'snp' in t:\n",
    "                return 'variant'\n",
    "            if 'chemical' in t or 'drug' in t:\n",
    "                return 'chemical'\n",
    "            return t\n",
    "        \n",
    "        t1 = normalize_type(type1)\n",
    "        t2 = normalize_type(type2)\n",
    "        \n",
    "        # Valid pairs\n",
    "        valid_pairs = [\n",
    "            ('disease', 'gene'),\n",
    "            ('gene', 'disease'),\n",
    "            ('disease', 'variant'),\n",
    "            ('variant', 'disease'),\n",
    "            ('gene', 'variant'),\n",
    "            ('variant', 'gene'),\n",
    "            ('chemical', 'disease'),\n",
    "            ('disease', 'chemical'),\n",
    "            ('chemical', 'gene'),\n",
    "            ('gene', 'chemical'),\n",
    "        ]\n",
    "        \n",
    "        return (t1, t2) in valid_pairs\n",
    "    \n",
    "    def _find_relation(self, id1, id2, relations):\n",
    "        \"\"\"Find relation between entities.\"\"\"\n",
    "        for rel in relations:\n",
    "            # Handle different relation formats\n",
    "            arg1_id = rel['arg1'].split(':')[-1] if ':' in rel['arg1'] else rel['arg1']\n",
    "            arg2_id = rel['arg2'].split(':')[-1] if ':' in rel['arg2'] else rel['arg2']\n",
    "            \n",
    "            if (arg1_id == id1 and arg2_id == id2) or (arg1_id == id2 and arg2_id == id1):\n",
    "                return rel['type']\n",
    "        \n",
    "        return 'No_Relation'\n",
    "\n",
    "print(\"✓ Fixed BioREDToBERTGTConverter defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ BERTGTDataset and collate_fn defined\n"
     ]
    }
   ],
   "source": [
    "class BERTGTDataset(Dataset):\n",
    "    \"\"\"Dataset for BERT-GT model.\"\"\"\n",
    "    \n",
    "    def __init__(self, examples, relation2id):\n",
    "        self.examples = examples\n",
    "        self.relation2id = relation2id\n",
    "        self.id2relation = {v: k for k, v in relation2id.items()}\n",
    "        self.num_relations = len(relation2id)\n",
    "        self.relation_types = list(relation2id.keys())\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        example = self.examples[idx]\n",
    "        \n",
    "        # Convert relation to ID\n",
    "        label = self.relation2id.get(example['label'], self.relation2id['No_Relation'])\n",
    "        \n",
    "        return {\n",
    "            'input_ids': torch.tensor(example['input_ids'], dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(example['attention_mask'], dtype=torch.long),\n",
    "            'entity1_start': example['entity1_start'],\n",
    "            'entity1_end': example['entity1_end'],\n",
    "            'entity2_start': example['entity2_start'],\n",
    "            'entity2_end': example['entity2_end'],\n",
    "            'entities': example['entities'],\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "\n",
    "def bert_gt_collate_fn(batch):\n",
    "    \"\"\"Custom collate function for BERT-GT.\"\"\"\n",
    "    input_ids = torch.stack([item['input_ids'] for item in batch])\n",
    "    attention_mask = torch.stack([item['attention_mask'] for item in batch])\n",
    "    labels = torch.stack([item['label'] for item in batch])\n",
    "    \n",
    "    entity1_start = [item['entity1_start'] for item in batch]\n",
    "    entity1_end = [item['entity1_end'] for item in batch]\n",
    "    entity2_start = [item['entity2_start'] for item in batch]\n",
    "    entity2_end = [item['entity2_end'] for item in batch]\n",
    "    entities = [item['entities'] for item in batch]\n",
    "    \n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attention_mask,\n",
    "        'entity1_start': entity1_start,\n",
    "        'entity1_end': entity1_end,\n",
    "        'entity2_start': entity2_start,\n",
    "        'entity2_end': entity2_end,\n",
    "        'entities': entities,\n",
    "        'labels': labels\n",
    "    }\n",
    "\n",
    "print(\"✓ BERTGTDataset and collate_fn defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training and Evaluation Functions with Checkpoint Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Training and evaluation functions loaded\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def get_latest_checkpoint(checkpoint_dir='checkpoints'):\n",
    "    \"\"\"\n",
    "    Find the latest checkpoint file automatically.\n",
    "    \n",
    "    Args:\n",
    "        checkpoint_dir: Directory containing checkpoints\n",
    "    \n",
    "    Returns:\n",
    "        Path to latest checkpoint, or None if no checkpoints found\n",
    "    \"\"\"\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        return None\n",
    "    \n",
    "    checkpoints = glob.glob(os.path.join(checkpoint_dir, 'checkpoint_epoch_*.pt'))\n",
    "    if not checkpoints:\n",
    "        return None\n",
    "    \n",
    "    # Sort by epoch number and get latest\n",
    "    latest = max(checkpoints, key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "    return latest\n",
    "\n",
    "\n",
    "def evaluate_bert_gt(model, data_loader, device, return_predictions=False):\n",
    "    \"\"\"\n",
    "    Evaluate BERT-GT model using sklearn.metrics.precision_recall_fscore_support.\n",
    "    \n",
    "    Reference:\n",
    "        https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    # Collect predictions\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc='Evaluating'):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            # Move entity positions to device\n",
    "            entity1_start = [x.to(device) if torch.is_tensor(x) else x for x in batch['entity1_start']]\n",
    "            entity1_end = [x.to(device) if torch.is_tensor(x) else x for x in batch['entity1_end']]\n",
    "            entity2_start = [x.to(device) if torch.is_tensor(x) else x for x in batch['entity2_start']]\n",
    "            entity2_end = [x.to(device) if torch.is_tensor(x) else x for x in batch['entity2_end']]\n",
    "            \n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                entity1_start=entity1_start,\n",
    "                entity1_end=entity1_end,\n",
    "                entity2_start=entity2_start,\n",
    "                entity2_end=entity2_end,\n",
    "                entities=batch['entities']\n",
    "            )\n",
    "            \n",
    "            logits = outputs['logits']\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics using precision_recall_fscore_support\n",
    "    # Macro average (treats all classes equally)\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
    "        all_labels,\n",
    "        all_preds,\n",
    "        average='macro',\n",
    "        zero_division=0\n",
    "    )\n",
    "    \n",
    "    # Weighted average (weights by class frequency)\n",
    "    precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(\n",
    "        all_labels,\n",
    "        all_preds,\n",
    "        average='weighted',\n",
    "        zero_division=0\n",
    "    )\n",
    "    \n",
    "    # Micro average (calculates metrics globally)\n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(\n",
    "        all_labels,\n",
    "        all_preds,\n",
    "        average='micro',\n",
    "        zero_division=0\n",
    "    )\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    # Prepare metrics dictionary\n",
    "    metrics = {\n",
    "        # Accuracy\n",
    "        'accuracy': accuracy,\n",
    "        \n",
    "        # F1 scores\n",
    "        'f1_macro': f1_macro,\n",
    "        'f1_weighted': f1_weighted,\n",
    "        'f1_micro': f1_micro,\n",
    "        \n",
    "        # Precision\n",
    "        'precision_macro': precision_macro,\n",
    "        'precision_weighted': precision_weighted,\n",
    "        'precision_micro': precision_micro,\n",
    "        \n",
    "        # Recall\n",
    "        'recall_macro': recall_macro,\n",
    "        'recall_weighted': recall_weighted,\n",
    "        'recall_micro': recall_micro\n",
    "    }\n",
    "    \n",
    "    # Include predictions and labels if requested\n",
    "    if return_predictions:\n",
    "        metrics['predictions'] = all_preds\n",
    "        metrics['labels'] = all_labels\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def train_bert_gt_with_checkpoints(\n",
    "    model, train_loader, val_loader, \n",
    "    num_epochs, learning_rate, device,\n",
    "    checkpoint_dir='checkpoints', resume='auto'\n",
    "):\n",
    "    \"\"\"\n",
    "    Train BERT-GT model with automatic checkpoint saving and resuming.\n",
    "    Args:\n",
    "        model: BERT-GT model\n",
    "        train_loader: Training DataLoader\n",
    "        val_loader: Validation DataLoader\n",
    "        num_epochs: Total number of epochs\n",
    "        learning_rate: Learning rate\n",
    "        device: Device to train on\n",
    "        checkpoint_dir: Directory to save checkpoints\n",
    "        resume: 'auto' (auto-resume from latest), \n",
    "                'fresh' (start from scratch),\n",
    "                or path to specific checkpoint\n",
    "    \n",
    "    Returns:\n",
    "        Training statistics list\n",
    "    \"\"\"\n",
    "    # Create checkpoint directory\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    \n",
    "    # Initialize optimizer with correct_bias=False\n",
    "    from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "    \n",
    "    optimizer = AdamW(\n",
    "        model.parameters(),\n",
    "        lr=learning_rate,\n",
    "        correct_bias=False  # Important for checkpoint compatibility\n",
    "    )\n",
    "    \n",
    "    # Initialize scheduler\n",
    "    total_steps = len(train_loader) * num_epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=total_steps // 10,\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "    \n",
    "    # Training state\n",
    "    start_epoch = 0\n",
    "    best_val_f1 = 0\n",
    "    training_stats = []\n",
    "    \n",
    "    # Determine which checkpoint to resume from\n",
    "    resume_from = None\n",
    "    if resume == 'auto':\n",
    "        resume_from = get_latest_checkpoint(checkpoint_dir)\n",
    "        if resume_from:\n",
    "            print(f\"AUTO-RESUME: Found checkpoint\")\n",
    "        else:\n",
    "            print(f\"NO CHECKPOINT FOUND: Starting fresh training\")\n",
    "    elif resume == 'fresh':\n",
    "        print(f\"FRESH START: Ignoring existing checkpoints\")\n",
    "    else:\n",
    "        # Specific checkpoint path provided\n",
    "        if os.path.exists(resume):\n",
    "            resume_from = resume\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"RESUMING FROM: {resume}\")\n",
    "            print(f\"{'='*60}\\n\")\n",
    "        else:\n",
    "            print(f\"⚠️  Checkpoint not found: {resume}\")\n",
    "            print(f\"Starting fresh training instead\")\n",
    "    \n",
    "    # Load checkpoint if found\n",
    "# Load checkpoint if found\n",
    "    if resume_from:\n",
    "        try:\n",
    "            checkpoint = torch.load(resume_from, weights_only=False)\n",
    "\n",
    "            # Restore model state (always works)\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            print(\"✓ Model state restored\")\n",
    "\n",
    "            # Check if optimizer state is compatible\n",
    "            if 'optimizer_state_dict' in checkpoint:\n",
    "                try:\n",
    "                    # Try to load optimizer state\n",
    "                    old_state = checkpoint['optimizer_state_dict']\n",
    "\n",
    "                    # Check if the state is compatible\n",
    "                    # Try to add correct_bias to all param groups if missing\n",
    "                    if 'param_groups' in old_state:\n",
    "                        for group in old_state['param_groups']:\n",
    "                            if 'correct_bias' not in group:\n",
    "                                group['correct_bias'] = False\n",
    "\n",
    "                    optimizer.load_state_dict(old_state)\n",
    "                    print(\"✓ Optimizer state restored (with compatibility fix)\")\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️  Could not restore optimizer state: {type(e).__name__}\")\n",
    "                    print(\"⚠️  Using fresh optimizer (momentum lost)\")\n",
    "\n",
    "            # Check if scheduler state is compatible\n",
    "            if 'scheduler_state_dict' in checkpoint:\n",
    "                try:\n",
    "                    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "                    print(\"✓ Scheduler state restored\")\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️  Could not restore scheduler state: {type(e).__name__}\")\n",
    "                    print(\"⚠️  Using fresh scheduler\")\n",
    "\n",
    "            # Restore training metadata\n",
    "            start_epoch = checkpoint['epoch'] + 1\n",
    "            best_val_f1 = checkpoint.get('best_val_f1', 0)\n",
    "            training_stats = checkpoint.get('training_stats', [])\n",
    "\n",
    "            print(f\"✓ Loaded checkpoint: {os.path.basename(resume_from)}\")\n",
    "            print(f\"✓ Resuming from epoch {start_epoch}\")\n",
    "            print(f\"✓ Best validation F1 so far: {best_val_f1:.4f}\")\n",
    "            print(f\"✓ Training history: {len(training_stats)} epochs\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error loading checkpoint: {e}\")\n",
    "            print(f\"Starting fresh training instead\")\n",
    "            start_epoch = 0\n",
    "            best_val_f1 = 0\n",
    "            training_stats = []\n",
    "\n",
    "        print(f\"{'='*60}\\n\")\n",
    "\n",
    "    else:\n",
    "        print(f\"✓ Starting fresh training\")\n",
    "        print(f\"✓ Checkpoints will be saved to: {checkpoint_dir}/\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "\n",
    "    # ============================================\n",
    "    # TRAINING LOOP\n",
    "    # ============================================\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        \n",
    "        train_pbar = tqdm(train_loader, desc='Training')\n",
    "        for batch in train_pbar:\n",
    "            # Move batch to device\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            # Move entity positions to device\n",
    "            entity1_start = [x.to(device) if torch.is_tensor(x) else x for x in batch['entity1_start']]\n",
    "            entity1_end = [x.to(device) if torch.is_tensor(x) else x for x in batch['entity1_end']]\n",
    "            entity2_start = [x.to(device) if torch.is_tensor(x) else x for x in batch['entity2_start']]\n",
    "            entity2_end = [x.to(device) if torch.is_tensor(x) else x for x in batch['entity2_end']]\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                entity1_start=entity1_start,\n",
    "                entity1_end=entity1_end,\n",
    "                entity2_start=entity2_start,\n",
    "                entity2_end=entity2_end,\n",
    "                entities=batch['entities'],\n",
    "                labels=labels\n",
    "            )\n",
    "            \n",
    "            loss = outputs['loss']\n",
    "            total_train_loss += loss.item()\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            train_pbar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        print(f\"\\nAverage training loss: {avg_train_loss:.4f}\")\n",
    "        \n",
    "        # Validation phase\n",
    "        val_metrics = evaluate_bert_gt(model, val_loader, device)\n",
    "        \n",
    "        print(f\"\\nValidation Metrics:\")\n",
    "        print(f\"  F1 (weighted): {val_metrics['f1_weighted']:.4f}\")\n",
    "        print(f\"  Precision (weighted): {val_metrics['precision_weighted']:.4f}\")\n",
    "        print(f\"  Recall (weighted): {val_metrics['recall_weighted']:.4f}\")\n",
    "        print(f\"  Accuracy: {val_metrics['accuracy']:.4f}\")\n",
    "        \n",
    "        # ============================================\n",
    "        # SAVE CHECKPOINT EVERY EPOCH\n",
    "        # ============================================\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch+1}.pt')\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'train_loss': avg_train_loss,\n",
    "            'val_f1': val_metrics['f1_weighted'],\n",
    "            'val_accuracy': val_metrics['accuracy'],\n",
    "            'best_val_f1': best_val_f1,\n",
    "            'training_stats': training_stats\n",
    "        }\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        print(f\"✓ Saved checkpoint: {os.path.basename(checkpoint_path)}\")\n",
    "        \n",
    "        # ============================================\n",
    "        # SAVE BEST MODEL SEPARATELY\n",
    "        # ============================================\n",
    "        if val_metrics['f1_weighted'] > best_val_f1:\n",
    "            best_val_f1 = val_metrics['f1_weighted']\n",
    "            torch.save(model.state_dict(), 'best_bert_gt_model.pt')\n",
    "            print(f\"✓ Saved best model with F1: {best_val_f1:.4f}\")\n",
    "        \n",
    "        # Update training stats\n",
    "        training_stats.append({\n",
    "            'epoch': epoch + 1,\n",
    "            'train_loss': avg_train_loss,\n",
    "            'val_f1_weighted': val_metrics['f1_weighted'],\n",
    "            'val_precision_weighted': val_metrics['precision_weighted'],\n",
    "            'val_recall_weighted': val_metrics['recall_weighted'],\n",
    "            'val_accuracy': val_metrics['accuracy']\n",
    "        })\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"TRAINING COMPLETE!\")\n",
    "    print(f\"Best validation F1: {best_val_f1:.4f}\")\n",
    "    print(f\"Total epochs trained: {len(training_stats)}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    return training_stats\n",
    "\n",
    "\n",
    "print(\"✓ Training and evaluation functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Load and Prepare Data\n",
    "\n",
    "Now we'll load the BioRED data and convert it to BERT-GT format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  TESTING MODE\n",
      "\n",
      "Configuration:\n",
      "  Max documents: 1000\n",
      "  Epochs: 3\n",
      "  Batch size: 4\n",
      "  Learning rate: 1e-05\n",
      "  Graph layers: 2\n",
      "  Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CONFIGURATION\n",
    "# ============================================\n",
    "\n",
    "import torch\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Set this to True for testing, False for full training\n",
    "TESTING = True\n",
    "\n",
    "# File paths (UPDATE THESE!)\n",
    "TRAIN_DATA_PATH = 'VARIOME/variome_output.pubtator'\n",
    "DEV_DATA_PATH = 'VARIOME/variome_output.pubtator'\n",
    "TEST_DATA_PATH = 'VARIOME/variome_output.pubtator'\n",
    "\n",
    "# Model settings\n",
    "MODEL_NAME = 'dmis-lab/biobert-v1.1'\n",
    "MAX_LENGTH = 512\n",
    "NUM_GRAPH_LAYERS = 2  # Number of Graph Transformer layers\n",
    "NUM_ATTENTION_HEADS = 4\n",
    "MAX_ENTITIES = 20\n",
    "DROPOUT = 0.1\n",
    "\n",
    "# Training settings\n",
    "if TESTING:\n",
    "    print(\"⚠️  TESTING MODE\")\n",
    "    MAX_DOCS = 1000  # Load 1000 docs for testing\n",
    "    NUM_EPOCHS = 3\n",
    "    BATCH_SIZE = 4\n",
    "    LEARNING_RATE = 1e-5\n",
    "else:\n",
    "    print(\"✓ FULL TRAINING MODE\")\n",
    "    MAX_DOCS = None  # Load all documents\n",
    "    NUM_EPOCHS = 15\n",
    "    BATCH_SIZE = 8\n",
    "    LEARNING_RATE = 1e-5\n",
    "\n",
    "# Relation types\n",
    "RELATION_TYPES = {\n",
    "    'Positive_Correlation': 0,\n",
    "    'Negative_Correlation': 1,\n",
    "    'Association': 2,\n",
    "    'No_Relation': 3\n",
    "}\n",
    "\n",
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"  Max documents: {MAX_DOCS or 'ALL'}\")\n",
    "print(f\"  Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"  Graph layers: {NUM_GRAPH_LAYERS}\")\n",
    "print(f\"  Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BioRED data...\n",
      "\n",
      "\n",
      "Loading: variome_output.pubtator\n",
      "  Loaded 100 documents...\r",
      "  Loaded 200 documents...\r",
      "  Loaded 300 documents...\r\n",
      "✓ Loaded 392 documents total\n",
      "\n",
      "Loading: variome_output.pubtator\n",
      "  Loaded 100 documents...\r",
      "  Loaded 200 documents...\r",
      "  Loaded 300 documents...\r\n",
      "✓ Loaded 392 documents total\n",
      "\n",
      "Loading: variome_output.pubtator\n",
      "  Loaded 100 documents...\r",
      "  Loaded 200 documents...\r",
      "  Loaded 300 documents...\r\n",
      "✓ Loaded 392 documents total\n",
      "\n",
      "✓ Loaded:\n",
      "  Train: 392 documents\n",
      "  Dev: 392 documents\n",
      "  Test: 392 documents\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "#              LOAD BIORED DATA \n",
    "# ============================================\n",
    "\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "\n",
    "class BioREDDataLoader:\n",
    "    \"\"\"\n",
    "    Loads and parses BioRED dataset in PubTator format.\n",
    "    \n",
    "    PubTator format:\n",
    "    - First line: PMID|t|Title\n",
    "    - Second line: PMID|a|Abstract\n",
    "    - Following lines: PMID\\tstart\\tend\\ttext\\ttype\\tid\n",
    "    - Relation lines: PMID\\trelation_type\\tArg1:entity_id\\tArg2:entity_id\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to .pubtator file, directory containing .pubtator files, or list of paths\n",
    "        max_documents: Maximum number of documents to load (None = load all)\n",
    "        skip_documents: Number of documents to skip from the beginning\n",
    "        verbose: Print loading progress\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, file_path, max_documents=None, skip_documents=0, verbose=True):\n",
    "        self.file_path = file_path\n",
    "        self.max_documents = max_documents\n",
    "        self.skip_documents = skip_documents\n",
    "        self.verbose = verbose\n",
    "        self.documents = []\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load and parse BioRED data from file(s).\"\"\"\n",
    "        # Determine if file_path is a file, directory, or list\n",
    "        if isinstance(self.file_path, list):\n",
    "            # List of file paths\n",
    "            file_paths = self.file_path\n",
    "            if self.verbose:\n",
    "                print(f\"Loading from {len(file_paths)} file(s)\")\n",
    "        elif os.path.isdir(self.file_path):\n",
    "            # Directory - get all .pubtator files\n",
    "            file_paths = sorted([\n",
    "                os.path.join(self.file_path, f) \n",
    "                for f in os.listdir(self.file_path) \n",
    "                if f.endswith('.pubtator')\n",
    "            ])\n",
    "            if self.verbose:\n",
    "                print(f\"Found {len(file_paths)} .pubtator file(s) in directory\")\n",
    "        else:\n",
    "            # Single file\n",
    "            file_paths = [self.file_path]\n",
    "        \n",
    "        if not file_paths:\n",
    "            print(\"Warning: No .pubtator files found!\")\n",
    "            return self.documents\n",
    "        \n",
    "        # Load documents from all files\n",
    "        docs_processed = 0\n",
    "        \n",
    "        for file_path in file_paths:\n",
    "            if self.verbose:\n",
    "                print(f\"\\nLoading: {os.path.basename(file_path)}\")\n",
    "            \n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    content = f.read().strip()\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Error: File not found - {file_path}\")\n",
    "                continue\n",
    "            \n",
    "            # Split by empty lines (documents are separated by empty lines)\n",
    "            doc_blocks = content.split('\\n\\n')\n",
    "            \n",
    "            for block in doc_blocks:\n",
    "                # Check if we should skip this document\n",
    "                if docs_processed < self.skip_documents:\n",
    "                    docs_processed += 1\n",
    "                    continue\n",
    "                \n",
    "                # Check if we've reached the maximum\n",
    "                if self.max_documents is not None and len(self.documents) >= self.max_documents:\n",
    "                    if self.verbose:\n",
    "                        print(f\"\\n✓ Reached max_documents limit ({self.max_documents})\")\n",
    "                    return self.documents\n",
    "                \n",
    "                if not block.strip():\n",
    "                    continue\n",
    "                    \n",
    "                doc = self._parse_document(block)\n",
    "                if doc:\n",
    "                    self.documents.append(doc)\n",
    "                    docs_processed += 1\n",
    "                    \n",
    "                    # Print progress every 100 documents\n",
    "                    if self.verbose and len(self.documents) % 100 == 0:\n",
    "                        print(f\"  Loaded {len(self.documents)} documents...\", end='\\r')\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"\\n✓ Loaded {len(self.documents)} documents total\")\n",
    "            if self.skip_documents > 0:\n",
    "                print(f\"  (Skipped first {self.skip_documents} documents)\")\n",
    "        \n",
    "        return self.documents\n",
    "    \n",
    "    def _parse_document(self, block):\n",
    "        \"\"\"Parse a single document block.\"\"\"\n",
    "        lines = block.strip().split('\\n')\n",
    "        if len(lines) < 2:\n",
    "            return None\n",
    "        \n",
    "        # Parse title and abstract\n",
    "        title_parts = lines[0].split('|t|')\n",
    "        abstract_parts = lines[1].split('|a|')\n",
    "        \n",
    "        if len(title_parts) < 2 or len(abstract_parts) < 2:\n",
    "            return None\n",
    "        \n",
    "        pmid = title_parts[0]\n",
    "        title = title_parts[1] if len(title_parts) > 1 else \"\"\n",
    "        abstract = abstract_parts[1] if len(abstract_parts) > 1 else \"\"\n",
    "        \n",
    "        text = title + \" \" + abstract\n",
    "        \n",
    "        # Parse entities and relations\n",
    "        entities = []\n",
    "        relations = []\n",
    "        \n",
    "        for line in lines[2:]:\n",
    "            parts = line.split('\\t')\n",
    "            if len(parts) >= 6:  # Entity annotation\n",
    "                entity = {\n",
    "                    'pmid': parts[0],\n",
    "                    'start': int(parts[1]),\n",
    "                    'end': int(parts[2]),\n",
    "                    'text': parts[3],\n",
    "                    'type': parts[4],\n",
    "                    'id': parts[5]\n",
    "                }\n",
    "                entities.append(entity)\n",
    "            elif len(parts) >= 4 and 'CID' not in parts[1]:  # Relation annotation\n",
    "                relation = {\n",
    "                    'pmid': parts[0],\n",
    "                    'type': parts[1],\n",
    "                    'arg1': parts[2],\n",
    "                    'arg2': parts[3]\n",
    "                }\n",
    "                relations.append(relation)\n",
    "        \n",
    "        return {\n",
    "            'pmid': pmid,\n",
    "            'title': title,\n",
    "            'abstract': abstract,\n",
    "            'text': text,\n",
    "            'entities': entities,\n",
    "            'relations': relations\n",
    "        }\n",
    "\n",
    "print(\"Loading BioRED data...\\n\")\n",
    "\n",
    "train_loader_data = BioREDDataLoader(TRAIN_DATA_PATH, max_documents=MAX_DOCS)\n",
    "dev_loader_data = BioREDDataLoader(DEV_DATA_PATH, max_documents=MAX_DOCS//2 if MAX_DOCS else None)\n",
    "test_loader_data = BioREDDataLoader(TEST_DATA_PATH, max_documents=MAX_DOCS//2 if MAX_DOCS else None)\n",
    "\n",
    "train_docs = train_loader_data.load_data()\n",
    "dev_docs = dev_loader_data.load_data()\n",
    "test_docs = test_loader_data.load_data()\n",
    "\n",
    "print(f\"\\n✓ Loaded:\")\n",
    "print(f\"  Train: {len(train_docs)} documents\")\n",
    "print(f\"  Dev: {len(dev_docs)} documents\")\n",
    "print(f\"  Test: {len(test_docs)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DIAGNOSTIC: Analyzing Loaded Documents\n",
      "============================================================\n",
      "\n",
      "TRAIN Documents:\n",
      "  Total documents: 392\n",
      "\n",
      "  First document (PMID: 02435117):\n",
      "    Title: Conclusion...\n",
      "    Text length: 487 chars\n",
      "    Entities: 16\n",
      "    Relations: 11\n",
      "\n",
      "  Entity Statistics:\n",
      "    Documents with entities: 80/392\n",
      "    Total entities: 2459\n",
      "    Entity types:\n",
      "      Concepts_Ideas: 89\n",
      "      Disorder: 83\n",
      "      Living_Beings: 58\n",
      "      Phenomena: 5\n",
      "      Physiology: 83\n",
      "      age: 15\n",
      "      body-part: 216\n",
      "      cohort-patient: 328\n",
      "      disease: 605\n",
      "      ethnicity: 36\n",
      "      gender: 9\n",
      "      gene: 599\n",
      "      mutation: 242\n",
      "      size: 91\n",
      "\n",
      "  Potential for RE pairs:\n",
      "    Disease: 0\n",
      "    Gene: 0\n",
      "    Variant: 0\n",
      "    Chemical: 0\n",
      "    Disease-Gene pairs possible: 0\n",
      "    Disease-Variant pairs possible: 0\n",
      "    Gene-Variant pairs possible: 0\n",
      "\n",
      "  Sample entities from first doc:\n",
      "    - gene: 'CTNNB1' (pos: 251-257, id: T1)\n",
      "    - cohort-patient: 'patients' (pos: 117-125, id: T3)\n",
      "    - ethnicity: 'Swedish' (pos: 109-116, id: T2)\n",
      "    - disease: 'tumors' (pos: 97-103, id: T6)\n",
      "    - mutation: 'stabilizing mutations' (pos: 258-279, id: T7)\n",
      "\n",
      "  Sample relations from first doc:\n",
      "    - has: T15 ↔ T14\n",
      "    - has: T9 ↔ T7\n",
      "    - has: T12 ↔ T5\n",
      "\n",
      "DEV Documents:\n",
      "  Total documents: 392\n",
      "\n",
      "  First document (PMID: 02435117):\n",
      "    Title: Conclusion...\n",
      "    Text length: 487 chars\n",
      "    Entities: 16\n",
      "    Relations: 11\n",
      "\n",
      "  Entity Statistics:\n",
      "    Documents with entities: 80/392\n",
      "    Total entities: 2459\n",
      "    Entity types:\n",
      "      Concepts_Ideas: 89\n",
      "      Disorder: 83\n",
      "      Living_Beings: 58\n",
      "      Phenomena: 5\n",
      "      Physiology: 83\n",
      "      age: 15\n",
      "      body-part: 216\n",
      "      cohort-patient: 328\n",
      "      disease: 605\n",
      "      ethnicity: 36\n",
      "      gender: 9\n",
      "      gene: 599\n",
      "      mutation: 242\n",
      "      size: 91\n",
      "\n",
      "  Potential for RE pairs:\n",
      "    Disease: 0\n",
      "    Gene: 0\n",
      "    Variant: 0\n",
      "    Chemical: 0\n",
      "    Disease-Gene pairs possible: 0\n",
      "    Disease-Variant pairs possible: 0\n",
      "    Gene-Variant pairs possible: 0\n",
      "\n",
      "  Sample entities from first doc:\n",
      "    - gene: 'CTNNB1' (pos: 251-257, id: T1)\n",
      "    - cohort-patient: 'patients' (pos: 117-125, id: T3)\n",
      "    - ethnicity: 'Swedish' (pos: 109-116, id: T2)\n",
      "    - disease: 'tumors' (pos: 97-103, id: T6)\n",
      "    - mutation: 'stabilizing mutations' (pos: 258-279, id: T7)\n",
      "\n",
      "  Sample relations from first doc:\n",
      "    - has: T15 ↔ T14\n",
      "    - has: T9 ↔ T7\n",
      "    - has: T12 ↔ T5\n",
      "\n",
      "TEST Documents:\n",
      "  Total documents: 392\n",
      "\n",
      "  First document (PMID: 02435117):\n",
      "    Title: Conclusion...\n",
      "    Text length: 487 chars\n",
      "    Entities: 16\n",
      "    Relations: 11\n",
      "\n",
      "  Entity Statistics:\n",
      "    Documents with entities: 80/392\n",
      "    Total entities: 2459\n",
      "    Entity types:\n",
      "      Concepts_Ideas: 89\n",
      "      Disorder: 83\n",
      "      Living_Beings: 58\n",
      "      Phenomena: 5\n",
      "      Physiology: 83\n",
      "      age: 15\n",
      "      body-part: 216\n",
      "      cohort-patient: 328\n",
      "      disease: 605\n",
      "      ethnicity: 36\n",
      "      gender: 9\n",
      "      gene: 599\n",
      "      mutation: 242\n",
      "      size: 91\n",
      "\n",
      "  Potential for RE pairs:\n",
      "    Disease: 0\n",
      "    Gene: 0\n",
      "    Variant: 0\n",
      "    Chemical: 0\n",
      "    Disease-Gene pairs possible: 0\n",
      "    Disease-Variant pairs possible: 0\n",
      "    Gene-Variant pairs possible: 0\n",
      "\n",
      "  Sample entities from first doc:\n",
      "    - gene: 'CTNNB1' (pos: 251-257, id: T1)\n",
      "    - cohort-patient: 'patients' (pos: 117-125, id: T3)\n",
      "    - ethnicity: 'Swedish' (pos: 109-116, id: T2)\n",
      "    - disease: 'tumors' (pos: 97-103, id: T6)\n",
      "    - mutation: 'stabilizing mutations' (pos: 258-279, id: T7)\n",
      "\n",
      "  Sample relations from first doc:\n",
      "    - has: T15 ↔ T14\n",
      "    - has: T9 ↔ T7\n",
      "    - has: T12 ↔ T5\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# DIAGNOSTIC: Check Documents Before Conversion\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DIAGNOSTIC: Analyzing Loaded Documents\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def diagnose_documents(docs, name):\n",
    "    \"\"\"Analyze documents to see what we have.\"\"\"\n",
    "    print(f\"\\n{name} Documents:\")\n",
    "    print(f\"  Total documents: {len(docs)}\")\n",
    "    \n",
    "    if len(docs) == 0:\n",
    "        print(\"  ❌ No documents loaded!\")\n",
    "        return\n",
    "    \n",
    "    # Check first document\n",
    "    first_doc = docs[0]\n",
    "    print(f\"\\n  First document (PMID: {first_doc['pmid']}):\")\n",
    "    print(f\"    Title: {first_doc['title'][:80]}...\")\n",
    "    print(f\"    Text length: {len(first_doc['text'])} chars\")\n",
    "    print(f\"    Entities: {len(first_doc['entities'])}\")\n",
    "    print(f\"    Relations: {len(first_doc['relations'])}\")\n",
    "    \n",
    "    # Count entity types\n",
    "    entity_types = {}\n",
    "    total_entities = 0\n",
    "    docs_with_entities = 0\n",
    "    \n",
    "    for doc in docs:\n",
    "        if len(doc['entities']) > 0:\n",
    "            docs_with_entities += 1\n",
    "        for ent in doc['entities']:\n",
    "            ent_type = ent['type']\n",
    "            entity_types[ent_type] = entity_types.get(ent_type, 0) + 1\n",
    "            total_entities += 1\n",
    "    \n",
    "    \n",
    "    print(f\"\\n  Entity Statistics:\")\n",
    "    print(f\"    Documents with entities: {docs_with_entities}/{len(docs)}\")\n",
    "    print(f\"    Total entities: {total_entities}\")\n",
    "    print(f\"    Entity types:\")\n",
    "    for ent_type, count in sorted(entity_types.items()):\n",
    "        print(f\"      {ent_type}: {count}\")\n",
    "    \n",
    "    # Check for valid pairs\n",
    "    disease = entity_types.get('Disease', 0)\n",
    "    gene = entity_types.get('Gene', 0) + entity_types.get('GeneOrGeneProduct', 0)\n",
    "    variant = entity_types.get('Variant', 0) + entity_types.get('SequenceVariant', 0)\n",
    "    chemical = entity_types.get('Chemical', 0) + entity_types.get('ChemicalEntity', 0)\n",
    "    \n",
    "    print(f\"\\n  Potential for RE pairs:\")\n",
    "    print(f\"    Disease: {disease}\")\n",
    "    print(f\"    Gene: {gene}\")\n",
    "    print(f\"    Variant: {variant}\")\n",
    "    print(f\"    Chemical: {chemical}\")\n",
    "    print(f\"    Disease-Gene pairs possible: {disease * gene}\")\n",
    "    print(f\"    Disease-Variant pairs possible: {disease * variant}\")\n",
    "    print(f\"    Gene-Variant pairs possible: {gene * variant}\")\n",
    "    \n",
    "    # Show sample entities from first doc\n",
    "    if len(first_doc['entities']) > 0:\n",
    "        print(f\"\\n  Sample entities from first doc:\")\n",
    "        for ent in first_doc['entities'][:5]:\n",
    "            print(f\"    - {ent['type']}: '{ent['text']}' (pos: {ent['start']}-{ent['end']}, id: {ent['id']})\")\n",
    "    \n",
    "    # Show sample relations\n",
    "    if len(first_doc['relations']) > 0:\n",
    "        print(f\"\\n  Sample relations from first doc:\")\n",
    "        for rel in first_doc['relations'][:3]:\n",
    "            print(f\"    - {rel['type']}: {rel['arg1']} ↔ {rel['arg2']}\")\n",
    "    \n",
    "    return entity_types\n",
    "\n",
    "# Diagnose all datasets\n",
    "train_entity_types = diagnose_documents(train_docs, \"TRAIN\")\n",
    "dev_entity_types = diagnose_documents(dev_docs, \"DEV\")\n",
    "test_entity_types = diagnose_documents(test_docs, \"TEST\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing BioBERT tokenizer...\n",
      "✓ Tokenizer loaded with 28996 tokens\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# INITIALIZE TOKENIZER\n",
    "# ============================================\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nInitializing BioBERT tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "print(f\"✓ Tokenizer loaded with {len(tokenizer)} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting data to BERT-GT format...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting to BERT-GT format:  25%|██▌       | 99/392 [00:00<00:00, 986.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  DEBUG: First document\n",
      "    Text: 'Conclusion By analyzing a large series of tumors from Swedish patients, this study further emphasize...'\n",
      "    Entities: 16\n",
      "    Relations: 11\n",
      "    Mapped entities: 11/16\n",
      "    First mapped entity: {'id': 'T1', 'type': 'gene', 'start': 60, 'end': 60, 'text': 'CTNNB1'}\n",
      "    Pairs created: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting to BERT-GT format: 100%|██████████| 392/392 [00:00<00:00, 971.35it/s] \n",
      "Converting to BERT-GT format: 100%|██████████| 392/392 [00:00<00:00, 967.49it/s] \n",
      "Converting to BERT-GT format: 100%|██████████| 392/392 [00:00<00:00, 963.64it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Converted:\n",
      "  Train: 5059 examples\n",
      "  Dev: 5059 examples\n",
      "  Test: 5059 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CONVERT TO BERT-GT FORMAT\n",
    "# ============================================\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nConverting data to BERT-GT format...\\n\")\n",
    "\n",
    "converter = BioREDToBERTGTConverter(tokenizer, max_seq_length=MAX_LENGTH)\n",
    "\n",
    "train_examples = converter.convert_documents(train_docs)\n",
    "dev_examples = converter.convert_documents(dev_docs)\n",
    "test_examples = converter.convert_documents(test_docs)\n",
    "\n",
    "print(f\"\\n✓ Converted:\")\n",
    "print(f\"  Train: {len(train_examples)} examples\")\n",
    "print(f\"  Dev: {len(dev_examples)} examples\")\n",
    "print(f\"  Test: {len(test_examples)} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating datasets...\n",
      "\n",
      "Dataset sizes:\n",
      "  Train: 5059 examples\n",
      "  Dev: 5059 examples\n",
      "  Test: 5059 examples\n",
      "  Relation types: {'Positive_Correlation': 0, 'Negative_Correlation': 1, 'Association': 2, 'No_Relation': 3}\n",
      "\n",
      "Creating DataLoaders...\n",
      "\n",
      "✓ DataLoaders created:\n",
      "  Train: 1265 batches\n",
      "  Dev: 1265 batches\n",
      "  Test: 1265 batches\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CREATE DATASETS AND DATALOADERS\n",
    "# ============================================\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class BERTGTDataset(Dataset):\n",
    "    def __init__(self, examples, relation_types):\n",
    "        self.examples = examples\n",
    "        self.relation_types = relation_types\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        example = self.examples[idx]\n",
    "        return example\n",
    "\n",
    "def bert_gt_collate_fn(batch):\n",
    "    \"\"\"Collate function to handle batching of variable-length data.\"\"\"\n",
    "    # This will depend on your example structure\n",
    "    # Basic version:\n",
    "    return batch\n",
    "\n",
    "print(\"\\nCreating datasets...\")\n",
    "\n",
    "train_dataset = BERTGTDataset(train_examples, RELATION_TYPES)\n",
    "dev_dataset = BERTGTDataset(dev_examples, RELATION_TYPES)\n",
    "test_dataset = BERTGTDataset(test_examples, RELATION_TYPES)\n",
    "\n",
    "print(f\"\\nDataset sizes:\")\n",
    "print(f\"  Train: {len(train_dataset)} examples\")\n",
    "print(f\"  Dev: {len(dev_dataset)} examples\")\n",
    "print(f\"  Test: {len(test_dataset)} examples\")\n",
    "print(f\"  Relation types: {train_dataset.relation_types}\")\n",
    "\n",
    "# Create DataLoaders\n",
    "print(\"\\nCreating DataLoaders...\")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=bert_gt_collate_fn\n",
    ")\n",
    "\n",
    "dev_loader = DataLoader(\n",
    "    dev_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=bert_gt_collate_fn\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=bert_gt_collate_fn\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ DataLoaders created:\")\n",
    "print(f\"  Train: {len(train_loader)} batches\")\n",
    "print(f\"  Dev: {len(dev_loader)} batches\")\n",
    "print(f\"  Test: {len(test_loader)} batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Initialize and Train BERT-GT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing BERT-GT model...\n",
      "\n",
      "✓ BERT-GT Model initialized:\n",
      "  Total parameters: 125,440,516\n",
      "  Trainable parameters: 125,440,516\n",
      "  Hidden size: 768\n",
      "  Graph layers: 2\n",
      "  Attention heads: 4\n",
      "  Max entities: 20\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# INITIALIZE BERT-GT MODEL\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nInitializing BERT-GT model...\")\n",
    "\n",
    "model = BERTGTModel(\n",
    "    model_name=MODEL_NAME,\n",
    "    num_relations=len(RELATION_TYPES),\n",
    "    num_graph_layers=NUM_GRAPH_LAYERS,\n",
    "    num_attention_heads=NUM_ATTENTION_HEADS,\n",
    "    max_entities=MAX_ENTITIES,\n",
    "    dropout=DROPOUT\n",
    ")\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\n✓ BERT-GT Model initialized:\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"  Hidden size: {model.hidden_size}\")\n",
    "print(f\"  Graph layers: {NUM_GRAPH_LAYERS}\")\n",
    "print(f\"  Attention heads: {NUM_ATTENTION_HEADS}\")\n",
    "print(f\"  Max entities: {MAX_ENTITIES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RESUMING FROM SPECIFIC CHECKPOINT\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "RESUMING FROM: checkpoints/checkpoint_epoch_14.pt\n",
      "============================================================\n",
      "\n",
      "✓ Model state restored\n",
      "✓ Optimizer state restored (with compatibility fix)\n",
      "✓ Scheduler state restored\n",
      "✓ Loaded checkpoint: checkpoint_epoch_14.pt\n",
      "✓ Resuming from epoch 14\n",
      "✓ Best validation F1 so far: 0.5275\n",
      "✓ Training history: 7 epochs\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Epoch 15/15\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 4367/21443 [32:24<2:10:17,  2.18it/s, loss=0.714]  "
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Train BERT-GT Model with Checkpoint Support\n",
    "# ============================================\n",
    "\"\"\"\n",
    "This cell demonstrates three ways to train:\n",
    "1. AUTO-RESUME: Automatically resume from latest checkpoint\n",
    "2. FRESH START: Start training from scratch\n",
    "3. SPECIFIC CHECKPOINT: Resume from a specific checkpoint\n",
    "\n",
    "Choose the option that fits your needs!\n",
    "\"\"\"\n",
    "\n",
    "# ============================================\n",
    "# OPTION 1: AUTO-RESUME (RECOMMENDED) ⭐\n",
    "# ============================================\n",
    "# Automatically resumes from latest checkpoint if found\n",
    "# Otherwise starts fresh training\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING WITH AUTO-RESUME\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "training_stats = train_bert_gt_with_checkpoints(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=dev_loader,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    device=device,\n",
    "    checkpoint_dir='checkpoints',\n",
    "    resume='auto'  # ← Automatically finds and resumes from latest checkpoint\n",
    " )\n",
    "\n",
    "print(\"\\n✓ Training complete!\")\n",
    "print(f\"✓ Trained {len(training_stats)} epochs\")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# OPTION 2: FRESH START\n",
    "# ============================================\n",
    "# Uncomment this to start fresh, ignoring any existing checkpoints\n",
    "\n",
    "# print(\"=\"*60)\n",
    "# print(\"TRAINING FROM SCRATCH\")\n",
    "# print(\"=\"*60)\n",
    "# \n",
    "# training_stats = train_bert_gt_with_checkpoints(\n",
    "#     model=model,\n",
    "#     train_loader=train_loader,\n",
    "#     val_loader=dev_loader,\n",
    "#     num_epochs=NUM_EPOCHS,\n",
    "#     learning_rate=LEARNING_RATE,\n",
    "#     device=device,\n",
    "#     checkpoint_dir='checkpoints',\n",
    "#     resume='fresh'  # ← Forces fresh start\n",
    "# )\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# OPTION 3: RESUME FROM SPECIFIC CHECKPOINT\n",
    "# ============================================\n",
    "#Uncomment this to resume from a specific checkpoint file\n",
    "\n",
    "#print(\"=\"*60)\n",
    "#print(\"RESUMING FROM SPECIFIC CHECKPOINT\")\n",
    "#print(\"=\"*60)\n",
    "# \n",
    "#training_stats = train_bert_gt_with_checkpoints(\n",
    "#     model=model,\n",
    "#     train_loader=train_loader,\n",
    "#    val_loader=dev_loader,\n",
    "#     num_epochs=NUM_EPOCHS,\n",
    "#     learning_rate=LEARNING_RATE,\n",
    "#    device=device,\n",
    "#    checkpoint_dir='checkpoints',\n",
    "#    resume='checkpoints/checkpoint_epoch_14.pt'  # ← Specific checkpoint\n",
    "#)\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# HELPER: Check Available Checkpoints\n",
    "# ============================================\n",
    "# Uncomment to see what checkpoints exist\n",
    "\n",
    "# import os\n",
    "# if os.path.exists('checkpoints'):\n",
    "#     checkpoints = sorted([f for f in os.listdir('checkpoints') if f.endswith('.pt')])\n",
    "#     print(\"\\nAvailable checkpoints:\")\n",
    "#     for ckpt in checkpoints:\n",
    "#         path = os.path.join('checkpoints', ckpt)\n",
    "#         size_mb = os.path.getsize(path) / (1024 * 1024)\n",
    "#         print(f\"  {ckpt} ({size_mb:.1f} MB)\")\n",
    "#     \n",
    "#     # Show latest\n",
    "#     latest = get_latest_checkpoint('checkpoints')\n",
    "#     if latest:\n",
    "#         print(f\"\\n✓ Latest checkpoint: {os.path.basename(latest)}\")\n",
    "# else:\n",
    "#     print(\"No checkpoints directory found\")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# SAVE TRAINING STATISTICS\n",
    "# ============================================\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_stats = pd.DataFrame(training_stats)\n",
    "\n",
    "# Save to CSV\n",
    "df_stats.to_csv('bert_gt_training_stats.csv', index=False)\n",
    "print(f\"\\n✓ Training statistics saved to: bert_gt_training_stats.csv\")\n",
    "\n",
    "# Display summary\n",
    "print(\"\\nTraining Summary:\")\n",
    "print(f\"  Total epochs: {len(training_stats)}\")\n",
    "print(f\"  Best F1 (weighted): {df_stats['val_f1_weighted'].max():.4f}\")\n",
    "print(f\"  Best epoch: {df_stats['val_f1_weighted'].idxmax() + 1}\")\n",
    "print(f\"  Final loss: {df_stats['train_loss'].iloc[-1]:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ TRAINING CELL COMPLETE\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of batch: <class 'dict'>\n",
      "Keys: dict_keys(['input_ids', 'attention_mask', 'entity1_start', 'entity1_end', 'entity2_start', 'entity2_end', 'entities', 'labels'])\n",
      "input_ids shape: torch.Size([4, 512])\n",
      "labels: tensor([3, 3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "def bert_gt_collate_fn(batch):\n",
    "    \"\"\"Custom collate function for BERT-GT.\"\"\"\n",
    "    # Convert lists to tensors if needed\n",
    "    input_ids = torch.stack([\n",
    "        item['input_ids'] if isinstance(item['input_ids'], torch.Tensor) \n",
    "        else torch.tensor(item['input_ids'], dtype=torch.long) \n",
    "        for item in batch\n",
    "    ])\n",
    "    attention_mask = torch.stack([\n",
    "        item['attention_mask'] if isinstance(item['attention_mask'], torch.Tensor) \n",
    "        else torch.tensor(item['attention_mask'], dtype=torch.long) \n",
    "        for item in batch\n",
    "    ])\n",
    "    \n",
    "    # Convert string labels to integers\n",
    "    labels = torch.stack([\n",
    "        item['label'] if isinstance(item['label'], torch.Tensor)\n",
    "        else torch.tensor(\n",
    "            RELATION_TYPES.get(item['label'], RELATION_TYPES.get('No_Relation', 0)) \n",
    "            if isinstance(item['label'], str) \n",
    "            else item['label'],\n",
    "            dtype=torch.long\n",
    "        )\n",
    "        for item in batch\n",
    "    ])\n",
    "    \n",
    "    entity1_start = [item['entity1_start'] for item in batch]\n",
    "    entity1_end = [item['entity1_end'] for item in batch]\n",
    "    entity2_start = [item['entity2_start'] for item in batch]\n",
    "    entity2_end = [item['entity2_end'] for item in batch]\n",
    "    entities = [item['entities'] for item in batch]\n",
    "    \n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attention_mask,\n",
    "        'entity1_start': entity1_start,\n",
    "        'entity1_end': entity1_end,\n",
    "        'entity2_start': entity2_start,\n",
    "        'entity2_end': entity2_end,\n",
    "        'entities': entities,\n",
    "        'labels': labels\n",
    "    }\n",
    "\n",
    "# Recreate the DataLoader\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=bert_gt_collate_fn\n",
    ")\n",
    "\n",
    "# Test it\n",
    "for batch in test_loader:\n",
    "    print(f\"Type of batch: {type(batch)}\")\n",
    "    if isinstance(batch, dict):\n",
    "        print(f\"Keys: {batch.keys()}\")\n",
    "        print(f\"input_ids shape: {batch['input_ids'].shape}\")\n",
    "        print(f\"labels: {batch['labels']}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading: variome_output.pubtator\n",
      "  Loaded 100 documents...\r",
      "  Loaded 200 documents...\r",
      "  Loaded 300 documents...\r\n",
      "✓ Loaded 392 documents total\n",
      "All relation types in full dataset:\n",
      "  'has': 1022\n",
      "  'Association': 226\n",
      "\n",
      "Total documents: 392\n",
      "Total relations: 1248\n"
     ]
    }
   ],
   "source": [
    "# Temporarily load ALL documents to see true counts\n",
    "from collections import Counter\n",
    "\n",
    "full_loader = BioREDDataLoader('VARIOME/variome_output.pubtator', max_documents=None)\n",
    "all_docs = full_loader.load_data()\n",
    "\n",
    "# Count relations across all documents\n",
    "label_counts = Counter()\n",
    "for doc in all_docs:\n",
    "    for rel in doc['relations']:\n",
    "        label_counts[rel['type']] += 1\n",
    "\n",
    "print(\"All relation types in full dataset:\")\n",
    "for label, count in label_counts.most_common():\n",
    "    print(f\"  '{label}': {count}\")\n",
    "print(f\"\\nTotal documents: {len(all_docs)}\")\n",
    "print(f\"Total relations: {sum(label_counts.values())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "\n",
      "Loading: variome_output.pubtator\n",
      "  Loaded 100 documents...\r",
      "  Loaded 200 documents...\r",
      "  Loaded 300 documents...\r\n",
      "✓ Loaded 392 documents total\n",
      "\n",
      "Loading: variome_output.pubtator\n",
      "  Loaded 100 documents...\r",
      "  Loaded 200 documents...\r",
      "  Loaded 300 documents...\r\n",
      "✓ Loaded 392 documents total\n",
      "\n",
      "Loading: variome_output.pubtator\n",
      "  Loaded 100 documents...\r",
      "  Loaded 200 documents...\r",
      "  Loaded 300 documents...\r\n",
      "✓ Loaded 392 documents total\n",
      "\n",
      "Converting to BERT-GT format...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting to BERT-GT format: 100%|██████████| 392/392 [00:00<00:00, 920.14it/s] \n",
      "Converting to BERT-GT format: 100%|██████████| 392/392 [00:00<00:00, 709.71it/s]\n",
      "Converting to BERT-GT format: 100%|██████████| 392/392 [00:00<00:00, 921.27it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating datasets...\n",
      "\n",
      "train dataset:\n",
      "  'No_Relation': 4903\n",
      "  'has': 133\n",
      "  'Association': 23\n",
      "\n",
      "dev dataset:\n",
      "  'No_Relation': 4903\n",
      "  'has': 133\n",
      "  'Association': 23\n",
      "\n",
      "test dataset:\n",
      "  'No_Relation': 4903\n",
      "  'has': 133\n",
      "  'Association': 23\n",
      "\n",
      "✓ DataLoaders ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Reload the data with MAX_DOCS = 1000\n",
    "print(\"Loading data...\")\n",
    "train_loader_data = BioREDDataLoader(TRAIN_DATA_PATH, max_documents=MAX_DOCS)\n",
    "dev_loader_data = BioREDDataLoader(DEV_DATA_PATH, max_documents=MAX_DOCS//2 if MAX_DOCS else None)\n",
    "test_loader_data = BioREDDataLoader(TEST_DATA_PATH, max_documents=MAX_DOCS//2 if MAX_DOCS else None)\n",
    "\n",
    "train_docs = train_loader_data.load_data()\n",
    "dev_docs = dev_loader_data.load_data()\n",
    "test_docs = test_loader_data.load_data()\n",
    "\n",
    "# 2. Convert to BERT-GT format\n",
    "print(\"\\nConverting to BERT-GT format...\")\n",
    "train_examples = converter.convert_documents(train_docs)\n",
    "dev_examples = converter.convert_documents(dev_docs)\n",
    "test_examples = converter.convert_documents(test_docs)\n",
    "\n",
    "# 3. Create datasets\n",
    "print(\"\\nCreating datasets...\")\n",
    "train_dataset = BERTGTDataset(train_examples, RELATION_TYPES)\n",
    "dev_dataset = BERTGTDataset(dev_examples, RELATION_TYPES)\n",
    "test_dataset = BERTGTDataset(test_examples, RELATION_TYPES)\n",
    "\n",
    "# 4. Check label distribution\n",
    "for name, dataset in [('train', train_dataset), ('dev', dev_dataset), ('test', test_dataset)]:\n",
    "    label_counts = {}\n",
    "    for item in dataset.examples:\n",
    "        label = item.get('label', 'MISSING')\n",
    "        label_counts[label] = label_counts.get(label, 0) + 1\n",
    "    \n",
    "    print(f\"\\n{name} dataset:\")\n",
    "    for label, count in sorted(label_counts.items(), key=lambda x: -x[1]):\n",
    "        print(f\"  '{label}': {count}\")\n",
    "\n",
    "# 5. Recreate DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=bert_gt_collate_fn)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=BATCH_SIZE, collate_fn=bert_gt_collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=bert_gt_collate_fn)\n",
    "\n",
    "print(f\"\\n✓ DataLoaders ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading best model...\n",
      "✓ Best model loaded\n",
      "\n",
      "Evaluating on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1265/1265 [1:53:30<00:00,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  F1 (weighted): 0.9682\n",
      "  Precision (weighted): 0.9923\n",
      "  Recall (weighted): 0.9458\n",
      "  Accuracy: 0.9458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# LOAD BEST MODEL AND EVALUATE\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nLoading best model...\")\n",
    "model.load_state_dict(torch.load('VARIOME/best_combo_bert_gt_model.pt', map_location=device))\n",
    "print(\"✓ Best model loaded\")\n",
    "\n",
    "print(\"\\nEvaluating on test set...\")\n",
    "test_metrics = evaluate_bert_gt(model, test_loader, device, return_predictions=True)\n",
    "print(f\"  F1 (weighted): {test_metrics['f1_weighted']:.4f}\")\n",
    "print(f\"  Precision (weighted): {test_metrics['precision_weighted']:.4f}\")\n",
    "print(f\"  Recall (weighted): {test_metrics['recall_weighted']:.4f}\")\n",
    "print(f\"  Accuracy: {test_metrics['accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Visualize Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Convert to DataFrame\n",
    "stats_df = pd.DataFrame(training_stats)\n",
    "\n",
    "# Plot\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Training loss\n",
    "ax1.plot(stats_df['epoch'], stats_df['train_loss'], marker='o', linewidth=2)\n",
    "ax1.set_xlabel('Epoch', fontsize=12)\n",
    "ax1.set_ylabel('Training Loss', fontsize=12)\n",
    "ax1.set_title('Training Loss Over Time', fontsize=14, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Validation metrics\n",
    "ax2.plot(stats_df['epoch'], stats_df['val_f1_weighted'], marker='o', linewidth=2, label='F1 Score')\n",
    "ax2.plot(stats_df['epoch'], stats_df['val_accuracy'], marker='s', linewidth=2, label='Accuracy')\n",
    "ax2.set_xlabel('Epoch', fontsize=12)\n",
    "ax2.set_ylabel('Score', fontsize=12)\n",
    "ax2.set_title('Validation Metrics Over Time', fontsize=14, fontweight='bold')\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('bert_gt_training_progress.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Training progress visualized\")\n",
    "print(\"  Saved as: bert_gt_training_progress.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save Training Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stats_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Save statistics\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m stats_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert_gt_training_stats.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m✓ Training statistics saved to: bert_gt_training_stats.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Display final stats\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stats_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Save statistics\n",
    "stats_df.to_csv('bert_gt_training_stats.csv', index=False)\n",
    "print(\"\\n✓ Training statistics saved to: bert_gt_training_stats.csv\")\n",
    "\n",
    "# Display final stats\n",
    "print(\"\\nTraining Statistics:\")\n",
    "print(stats_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Evaluation results saved to: VARIOME/evaluation_results.csv\n",
      "\n",
      "Evaluation Results:\n",
      "dataset  f1_weighted  precision_weighted  recall_weighted  accuracy\n",
      "VARIOME     0.968182            0.992287         0.945839  0.945839\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a dataframe from the test metrics\n",
    "results_df = pd.DataFrame([{\n",
    "    'dataset': 'VARIOME',\n",
    "    'f1_weighted': test_metrics['f1_weighted'],\n",
    "    'precision_weighted': test_metrics['precision_weighted'],\n",
    "    'recall_weighted': test_metrics['recall_weighted'],\n",
    "    'accuracy': test_metrics['accuracy']\n",
    "}])\n",
    "\n",
    "# Save it\n",
    "results_df.to_csv('VARIOME/evaluation_results.csv', index=False)\n",
    "print(\"✓ Evaluation results saved to: VARIOME/evaluation_results.csv\")\n",
    "\n",
    "# Display\n",
    "print(\"\\nEvaluation Results:\")\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "BERT-GT MODEL SUMMARY\n",
      "======================================================================\n",
      "\n",
      "📐 Model Architecture:\n",
      "  Base Model: BioBERT v1.1\n",
      "  Graph Transformer Layers: 2\n",
      "  Attention Heads: 4\n",
      "  Max Entities per Document: 20\n",
      "  Total Parameters: 125,440,516\n",
      "\n",
      "⚙️  Training Configuration:\n",
      "  Training Documents: 392\n",
      "  Training Examples: 5059\n",
      "  Epochs: 3\n",
      "  Batch Size: 4\n",
      "  Learning Rate: 1e-05\n",
      "  Device: cpu\n",
      "\n",
      "📊 Test Set Performance:\n",
      "======================================================================\n",
      "\n",
      "  Overall Metrics:\n",
      "    Accuracy:            0.9458 (94.58%)\n",
      "\n",
      "  F1 Scores:\n",
      "    Macro:               0.2578 (25.78%)\n",
      "    Weighted:            0.9682 (96.82%)\n",
      "    Micro:               0.9458 (94.58%)\n",
      "\n",
      "  Precision:\n",
      "    Macro:               0.2577 (25.77%)\n",
      "    Weighted:            0.9923 (99.23%)\n",
      "    Micro:               0.9458 (94.58%)\n",
      "\n",
      "  Recall:\n",
      "    Macro:               0.2916 (29.16%)\n",
      "    Weighted:            0.9458 (94.58%)\n",
      "    Micro:               0.9458 (94.58%)\n",
      "\n",
      "  Per-Class Performance:\n",
      "  ----------------------------------------------------------------------\n",
      "  Relation                   Precision     Recall   F1-Score  Support\n",
      "  ----------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'BERTGTDataset' object has no attribute 'id2relation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 106\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m70\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# Get relation names\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m id2relation \u001b[38;5;241m=\u001b[39m test_dataset\u001b[38;5;241m.\u001b[39mid2relation\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(id2relation)):\n\u001b[1;32m    109\u001b[0m     relation_name \u001b[38;5;241m=\u001b[39m id2relation[i]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BERTGTDataset' object has no attribute 'id2relation'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BERT-GT MODEL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================\n",
    "# MODEL ARCHITECTURE\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n📐 Model Architecture:\")\n",
    "print(f\"  Base Model: BioBERT v1.1\")\n",
    "print(f\"  Graph Transformer Layers: {NUM_GRAPH_LAYERS}\")\n",
    "print(f\"  Attention Heads: {NUM_ATTENTION_HEADS}\")\n",
    "print(f\"  Max Entities per Document: {MAX_ENTITIES}\")\n",
    "print(f\"  Total Parameters: {total_params:,}\")\n",
    "\n",
    "# ============================================\n",
    "# TRAINING CONFIGURATION\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n⚙️  Training Configuration:\")\n",
    "print(f\"  Training Documents: {len(train_docs)}\")\n",
    "print(f\"  Training Examples: {len(train_dataset)}\")\n",
    "print(f\"  Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"  Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"  Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"  Device: {device}\")\n",
    "\n",
    "# ============================================\n",
    "# CALCULATE COMPREHENSIVE METRICS\n",
    "# ============================================\n",
    "\n",
    "# Get predictions and labels from test_metrics\n",
    "predictions = test_metrics['predictions']\n",
    "labels = test_metrics['labels']\n",
    "\n",
    "# Calculate metrics using precision_recall_fscore_support\n",
    "# This efficiently computes precision, recall, F1, and support in one call\n",
    "precision_per_class, recall_per_class, f1_per_class, support_per_class = precision_recall_fscore_support(\n",
    "    labels,\n",
    "    predictions,\n",
    "    average=None,  # Return per-class metrics\n",
    "    zero_division=0\n",
    ")\n",
    "\n",
    "# Calculate averaged metrics\n",
    "precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
    "    labels,\n",
    "    predictions,\n",
    "    average='macro',\n",
    "    zero_division=0\n",
    ")\n",
    "\n",
    "precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(\n",
    "    labels,\n",
    "    predictions,\n",
    "    average='weighted',\n",
    "    zero_division=0\n",
    ")\n",
    "\n",
    "precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(\n",
    "    labels,\n",
    "    predictions,\n",
    "    average='micro',\n",
    "    zero_division=0\n",
    ")\n",
    "\n",
    "# ============================================\n",
    "# DISPLAY OVERALL METRICS\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n📊 Test Set Performance:\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "print(f\"\\n  Overall Metrics:\")\n",
    "print(f\"    Accuracy:            {test_metrics['accuracy']:.4f} ({test_metrics['accuracy']*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\n  F1 Scores:\")\n",
    "print(f\"    Macro:               {f1_macro:.4f} ({f1_macro*100:.2f}%)\")\n",
    "print(f\"    Weighted:            {f1_weighted:.4f} ({f1_weighted*100:.2f}%)\")\n",
    "print(f\"    Micro:               {f1_micro:.4f} ({f1_micro*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\n  Precision:\")\n",
    "print(f\"    Macro:               {precision_macro:.4f} ({precision_macro*100:.2f}%)\")\n",
    "print(f\"    Weighted:            {precision_weighted:.4f} ({precision_weighted*100:.2f}%)\")\n",
    "print(f\"    Micro:               {precision_micro:.4f} ({precision_micro*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\n  Recall:\")\n",
    "print(f\"    Macro:               {recall_macro:.4f} ({recall_macro*100:.2f}%)\")\n",
    "print(f\"    Weighted:            {recall_weighted:.4f} ({recall_weighted*100:.2f}%)\")\n",
    "print(f\"    Micro:               {recall_micro:.4f} ({recall_micro*100:.2f}%)\")\n",
    "\n",
    "# ============================================\n",
    "# DISPLAY PER-CLASS METRICS\n",
    "# ============================================\n",
    "\n",
    "print(f\"\\n  Per-Class Performance:\")\n",
    "print(f\"  {'-'*70}\")\n",
    "print(f\"  {'Relation':<25s} {'Precision':>10s} {'Recall':>10s} {'F1-Score':>10s} {'Support':>8s}\")\n",
    "print(f\"  {'-'*70}\")\n",
    "\n",
    "# Get relation names\n",
    "id2relation = test_dataset.id2relation\n",
    "\n",
    "for i in range(len(id2relation)):\n",
    "    relation_name = id2relation[i]\n",
    "    print(f\"  {relation_name:<25s} \"\n",
    "          f\"{precision_per_class[i]:>10.4f} \"\n",
    "          f\"{recall_per_class[i]:>10.4f} \"\n",
    "          f\"{f1_per_class[i]:>10.4f} \"\n",
    "          f\"{support_per_class[i]:>8d}\")\n",
    "\n",
    "print(f\"  {'-'*70}\")\n",
    "\n",
    "# ============================================\n",
    "# IDENTIFY BEST AND WORST CLASSES\n",
    "# ============================================\n",
    "\n",
    "best_f1_idx = np.argmax(f1_per_class)\n",
    "worst_f1_idx = np.argmin(f1_per_class)\n",
    "\n",
    "print(f\"\\n  📈 Best performing class:\")\n",
    "print(f\"     {id2relation[best_f1_idx]}\")\n",
    "print(f\"     F1: {f1_per_class[best_f1_idx]:.4f}, \"\n",
    "      f\"Precision: {precision_per_class[best_f1_idx]:.4f}, \"\n",
    "      f\"Recall: {recall_per_class[best_f1_idx]:.4f}\")\n",
    "\n",
    "print(f\"\\n  📉 Worst performing class:\")\n",
    "print(f\"     {id2relation[worst_f1_idx]}\")\n",
    "print(f\"     F1: {f1_per_class[worst_f1_idx]:.4f}, \"\n",
    "      f\"Precision: {precision_per_class[worst_f1_idx]:.4f}, \"\n",
    "      f\"Recall: {recall_per_class[worst_f1_idx]:.4f}\")\n",
    "\n",
    "# ============================================\n",
    "# CONFUSION MATRIX\n",
    "# ============================================\n",
    "\n",
    "print(f\"\\n  🔢 Confusion Matrix:\")\n",
    "print(f\"  {'-'*70}\")\n",
    "\n",
    "cm = confusion_matrix(labels, predictions)\n",
    "relation_names = [id2relation[i] for i in range(len(id2relation))]\n",
    "\n",
    "# Header\n",
    "print(f\"\\n  {'Predicted →':<20s}\", end='')\n",
    "for name in relation_names:\n",
    "    print(f\"{name[:10]:>10s}\", end=' ')\n",
    "print()\n",
    "print(f\"  {'True ↓':<20s}\" + \"-\" * (11 * len(relation_names)))\n",
    "\n",
    "# Rows\n",
    "for i, name in enumerate(relation_names):\n",
    "    print(f\"  {name[:20]:<20s}\", end='')\n",
    "    for j in range(len(relation_names)):\n",
    "        print(f\"{cm[i][j]:>10d}\", end=' ')\n",
    "    print()\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "\n",
    "# ============================================\n",
    "# PERFORMANCE INTERPRETATION\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n💡 Performance Interpretation:\")\n",
    "\n",
    "if f1_weighted < 0.50:\n",
    "    status = \"⚠️  Below baseline\"\n",
    "    action = \"Increase training data or adjust hyperparameters\"\n",
    "elif f1_weighted < 0.60:\n",
    "    status = \"⚠️  Below expected\"\n",
    "    action = \"Train longer or load more documents\"\n",
    "elif f1_weighted < 0.70:\n",
    "    status = \"✓ Good performance (testing mode)\"\n",
    "    action = \"Run full training for better results\"\n",
    "elif f1_weighted < 0.75:\n",
    "    status = \"✓✓ Excellent performance (state-of-the-art)\"\n",
    "    action = \"Consider this model production-ready\"\n",
    "else:\n",
    "    status = \"✓✓✓ Outstanding performance!\"\n",
    "    action = \"This exceeds paper results - great work!\"\n",
    "\n",
    "print(f\"  Status: {status}\")\n",
    "print(f\"  Action: {action}\")\n",
    "\n",
    "# ============================================\n",
    "# OUTPUT FILES\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n📁 Output Files:\")\n",
    "print(f\"  Best Model:          best_bert_gt_model.pt\")\n",
    "print(f\"  Training Stats:      bert_gt_training_stats.csv\")\n",
    "print(f\"  Training Plot:       bert_gt_training_progress.png\")\n",
    "print(f\"  Detailed Metrics:    bert_gt_detailed_metrics.json\")\n",
    "\n",
    "# ============================================\n",
    "# SAVE DETAILED METRICS TO JSON\n",
    "# ============================================\n",
    "\n",
    "# Prepare detailed metrics dictionary\n",
    "detailed_metrics = {\n",
    "    # Overall metrics\n",
    "    'accuracy': float(test_metrics['accuracy']),\n",
    "    \n",
    "    # Macro averages\n",
    "    'f1_macro': float(f1_macro),\n",
    "    'precision_macro': float(precision_macro),\n",
    "    'recall_macro': float(recall_macro),\n",
    "    \n",
    "    # Weighted averages\n",
    "    'f1_weighted': float(f1_weighted),\n",
    "    'precision_weighted': float(precision_weighted),\n",
    "    'recall_weighted': float(recall_weighted),\n",
    "    \n",
    "    # Micro averages\n",
    "    'f1_micro': float(f1_micro),\n",
    "    'precision_micro': float(precision_micro),\n",
    "    'recall_micro': float(recall_micro),\n",
    "    \n",
    "    # Per-class metrics\n",
    "    'per_class': {}\n",
    "}\n",
    "\n",
    "# Add per-class metrics\n",
    "for i in range(len(id2relation)):\n",
    "    relation_name = id2relation[i]\n",
    "    detailed_metrics['per_class'][relation_name] = {\n",
    "        'precision': float(precision_per_class[i]),\n",
    "        'recall': float(recall_per_class[i]),\n",
    "        'f1': float(f1_per_class[i]),\n",
    "        'support': int(support_per_class[i])\n",
    "    }\n",
    "\n",
    "# Add confusion matrix\n",
    "detailed_metrics['confusion_matrix'] = cm.tolist()\n",
    "\n",
    "# Save to JSON file\n",
    "with open('bert_gt_detailed_metrics.json', 'w') as f:\n",
    "    json.dump(detailed_metrics, f, indent=2)\n",
    "\n",
    "print(\"\\n✓ Detailed metrics saved to: bert_gt_detailed_metrics.json\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✓ Model summary complete!\")\n",
    "print(\"=\"*70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset attributes:\n",
      "['examples', 'relation_types']\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset attributes:\")\n",
    "print([attr for attr in dir(test_dataset) if not attr.startswith('_')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in test_metrics:\n",
      "dict_keys(['accuracy', 'f1_macro', 'f1_weighted', 'f1_micro', 'precision_macro', 'precision_weighted', 'precision_micro', 'recall_macro', 'recall_weighted', 'recall_micro', 'predictions', 'labels'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Keys in test_metrics:\")\n",
    "print(test_metrics.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Per-Class Performance:\n",
      "======================================================================\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "Positive_Correlation       0.00      0.00      0.00         0\n",
      "Negative_Correlation       0.00      0.00      0.00         0\n",
      "         Association       0.03      0.22      0.06        23\n",
      "         No_Relation       1.00      0.95      0.97      5036\n",
      "\n",
      "            accuracy                           0.95      5059\n",
      "           macro avg       0.26      0.29      0.26      5059\n",
      "        weighted avg       0.99      0.95      0.97      5059\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Create id2relation mapping\n",
    "id2relation = {v: k for k, v in RELATION_TYPES.items()}\n",
    "target_names = [id2relation[i] for i in range(len(RELATION_TYPES))]\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nPer-Class Performance:\")\n",
    "print(\"=\" * 70)\n",
    "print(classification_report(\n",
    "    test_metrics['labels'], \n",
    "    test_metrics['predictions'], \n",
    "    target_names=target_names, \n",
    "    zero_division=0\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
